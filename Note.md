# Artificial Intelligence

## 知识表示和推理

### 前置知识

1. 项：常量、变量和函数

2. ==**置换**==：置换是形如 $\{x_1/t_1, x_2/t_2, \ldots, x_n/t_n\}$ 的有限集合，其中：

   - $\{x_1, x_2, \ldots, x_n\}$ 是互不相同的变量

   - $\{t_1, t_2, \ldots, t_n\}$ 是项（常量、变量或函数）

   - $x_i/t_i$ 表示用 $t_i$ 置换 $x_i$，其==**合法的前提**==是：

     1. 不允许 $t_i$ 和 $x_i$ 相同

     2. 不允许 $x_i$ 出现在 $t_i$ 中，

     3. ==也不允许出现循环置换==

        如：$\{x /y \} \text{和} \{x/f(y), y/{f(x)}\}$

   注意：置换中的每个变量替换是同时进行的

   > 对于 $P(x, g(y, z))$，做置换 $\{x/y, y/f(a)\}$，
   >
   > 即 $P(x, g(y, z)) \{x/y, y/f(a)\} \Rightarrow P(y, g(f(a), z))$

3. 文字：原子公式及其否定

   - $ P $：正文字；$ \neg P $：负文字

   子句：任何文字的析取。某个文字本身也都是子句。

   - $ P \vee \neg Q $ 记作 $ (P, \neg Q) $
   - 空子句：不包含任何文字的子句，记作 NIL
     - 空子句是永假的，不可满足的。

   子句集：由子句构成的集合（子句的合取）

   - $ (P \vee \neg Q) \wedge (P \vee R) $ 记作 $ \{(P, \neg Q), (P, R)\} $

****

特殊符号

1. `⊢*Am`  或者 ``⊢Am`` ：

   公式序列 A1, A2, ..., Am 称作Am的一个证明，如果 Ai (1 ≤ i ≤ m)：
   - 或者是公理；
   - 或者由Aj1, ..., Ajk (j1, ..., jk < i)用推理规则推得。

   当这样的证明存在时，称Am为系统的定理，记作 `|-*Am`（*是形式系统的名称），或者简记为 |-Am

2. `Γ⊢*Am` 或者 `Γ⊢Am`：

   设 Γ 为一公式集合。公式序列 A1, A2, ..., Am 称作 Am 的以 Γ 为前提的演绎，如果 Ai (1 ≤ i ≤ m)：

   - 或者是 Γ 中的公式
   - 或者是公理
   - 或者由 Aj1, ..., Ajk (j1, ..., jk < i) 用推理规则推得。

   当有这样的演绎时，Am 称作 Γ 的演绎结果，记作 `Γ⊢*Am`（*是形式系统的名称），或者简记为 `Γ⊢Am`，称 Γ 和 Γ 的成员为 Am 的前提

3. $\models_i$ 或者 $ \models $：

   如果推理算法 $ i $ 可以根据 $ KB $ 导出结论 $ \alpha $，则形式化地记为：$ KB \models_i \alpha $

   将 $ S $ 逻辑上蕴含 $ C $ 记为 $ S \models C $

4. $\vdash$：

   记某个永真的子句集合为 $ S $，需要推理得到的子句为 $ C $，基于归结的推理过程从 $ S $ 推导出 $ C $ 记为 $ S \vdash C $

### 归结推理

1. 归结式：对于任意两个子句 $C_1$ 和 $C_2$，若 $C_1$ 中有一个文字 $L$，而 $C_2$ 中有一个与 $L$ 成互补的文字 $\neg L$，则分别从 $C_1$ 和 $C_2$ 中删去 $L$ 和 $\neg L$，并将其剩余部分组成新的析取式。这个新的子句被称为 $C_1$ 和 $C_2$ 关于 $L$ 的归结式，$C_1$ 和 $C_2$ 则是该归结式的亲本子句。

   * 子句 $P$ 和 $\neg P$ 的归结式为空子句
   * 子句 $(W, R, Q)$ 和 $(W, S, \neg R)$ 的归结式为 $(W, Q, S)$

   **定理**：两个子句的归结式是这两个子句集的逻辑推论，如 $\{(P, C_1), (\neg P, C_2)\} \models (C_1, C_2)$

2. 如果 $ S \vdash C $，那么 $ S \models C $

   如果 $ S \vdash NIL $，那么 $ S \models NIL $，反之亦然

3. 鲁滨逊归结原理：检查子句集 S 中是否包含空子句，若包含，则 S 不可满足；若不包含，则在 S 中选择合适的子句进行归结，一旦归结出空子句，就说明 S 是不可满足的

5. 合一：在谓词逻辑的归结过程中，寻找项之间合适的变量置换使表达式一致，这个过程称为合一。

   * 用 $ \sigma = \{x_1/t_1, x_2/t_2, \ldots, x_n/t_n\} $ 来表示任一置换。用 $ \sigma $ 对表达式（语句）$ S $ 作置换后的例简记为 $ S\sigma $。

   * 可以对表达式多次置换：如用 $ \theta $ 和 $ \sigma $ 依次对 $ S $ 进行置换，记为 $ (S\theta)\sigma $。其结果等价于先将这两个置换合成（组合）为一个置换，即 $ \theta\sigma $，再用合成置换对 $ S $ 进行置换，即 $ S(\theta\sigma) $

6. 置换复合的过程：

   设 $ \theta = \{x_1/t_1, x_2/t_2, \ldots, x_n/t_n\} $，$ \sigma = \{y_1/u_1, y_2/u_2, \ldots, y_n/u_n\} $

   1. 构成 $\{x_1/t_1 \sigma, \ldots, x_n/ t_n\sigma, y_1/u_1, \ldots, y_m/u_m\}$；
   2. 如果 $y_j \in (x_1, \ldots, x_n)$，则删除 $y_j/u_j$；
   3. 如果 $t_k \sigma = x_k$，则删除 $x_k / t_k \sigma$;

   > 置换的合成公式比较复杂，不妨看个例子
   >
   > 令 $\theta = \{x / f(y), y / z\}, \sigma = \{x / a, y / b, z / y\}$
   >
   > 步骤1：$\theta \sigma = \{x / f(b), y / y, x / a, y / b, z / y\}$
   >
   > 步骤2：删除 $x / a$ 和 $y / b$
   >
   > 步骤3：删除 $y / y$
   >
   > $\theta \sigma = \{x / f(b), z / y\}$

7. 合一项：对于两个语句 $ f $ 和 $ g $，合一项是使得语句 $ f $ 和 $ g $ 等价的一个置换 $ \sigma $。

   最一般合一项：两个语句 $ f $ 和 $ g $ 的最一般合一项 $ \sigma $ 满足：

   - $ \sigma $ 是 $ f $ 和 $ g $ 的一个合一项
   - 对于 $ f $ 和 $ g $ 的任意其它合一项 $ \theta $，存在一个替换 $ \lambda $ 使得 $ \theta = \sigma \lambda $

8. 求最一般合一项：

   给定两个语句 $ f $ 和 $ g $，

   1. 初始化：$ \sigma = \{\}, S = \{f, g\} $
   2. 如果 $ S $ 包含相同的语句，那么停止算法：当前的置换 $ \sigma $ 为语句 $ f $ 和 $ g $ 的最一般合一项目
   3. 否则，找出 $ S $ 的差异集 $ D = \{e_1, e_2\} $：
      - 若 $ e_1 = v $ 是一个变量且 $ e_2 = t $ 是一个不包含 $ v $ 的项，那么令 $ \sigma = \sigma \cup \{v/t\} $，$ S = S \{v/t\} $。返回步骤 2
      - 否则，停止算法：语句 $ f $ 和 $ g $ 不可合一

9. 谓词公式化为子句集的步骤：

   以将下列谓词公式化为子句集为例：$\forall x \Big( \forall y P(x, y) \rightarrow \neg \forall y \big(Q(x, y) \rightarrow R(x, y)\big) \Big)$

   1. 消去谓词公式中的 “→” 和 “↔”
      $$
      \forall x \Big( \neg \forall y P(x, y) \vee \neg \forall y \big( \neg Q(x, y) \vee R(x, y) \big) \Big) \tag{1}
      $$

   2. 把否定符号移到紧靠谓词的位置上，减少否定符号的辖域。
      $$
      \forall x \Big( \exists y \neg P(x, y) \vee \exists y \big( Q(x, y) \wedge \neg R(x, y) \big) \Big) \tag{2}
      $$

   3. 变量标准化：重新命名变元，使每个量词采用不同的变元，从而使不同量词的约束变元有不同的名字。
      $$
      \forall x \Big( \exists y \neg P(x, y) \vee \exists z \big( Q(x, z) \wedge \neg R(x, z) \big) \Big) \tag{3}
      $$

   4. 消去存在量词

      分两种情况：
      $$
      \begin{cases} 
      \exists x \forall y \Big(\neg P(x, z) \vee R \big(x, y, f(a)\big) \Big) \Rightarrow \forall y \Big(\neg P \big(b, g(y) \big) \vee R\big(b, y, f(a)\big)\Big) \\[2ex]
      \forall x_1 \forall x_2 \ldots \forall x_n \exists y P(x_1, x_2, \ldots, x_n, y) \Rightarrow \forall x_1 \forall x_2 \ldots \forall x_n  P(x_1, x_2, \ldots, x_n, f(x_1, x_2, \dots, x_n))
      \end{cases}
      $$
      原式化为：
      $$
      \forall x \bigg( \neg P\big(x, f(x) \big) \vee \Big(Q\big(x, g(x)\big) \wedge \neg R\big(x, g(x)\big) \Big) \bigg) \tag{4}
      $$
      
   5. 化为前束范式
   
   6. 化为合取范式
      $$
      \forall x \bigg( \Big(\neg P\big(x, f(x)\big) \vee Q\big(x, g(x)\big)\Big) \wedge \Big(\neg P\big(x, f(x)\big) \vee \neg R\big(x, g(x)\big)\Big) \bigg) \tag{5}
      $$
   
   7. 略去全称量词
      $$
      \Big(\neg P\big(x, f(x)\big) \vee Q\big(x, g(x)\big)\Big) \wedge \Big(\neg P\big(x, f(x)\big) \vee \neg R\big(x, g(x)\big)\Big) \tag{6}
      $$
   
   8. 消去合取词，把母式用子句集表示
      $$
      \bigg\{\Big(\neg P\big(x, f(x)\big), Q\big(x, g(x)\big)\Big), \Big(\neg P\big(x, f(x)\big), \neg R\big(x, g(x)\big)\Big)\bigg\} \tag{7}
      $$
   
   9. 子句变量标准化，即使每个子句中的变量符号不同
      $$
      \bigg\{\Big(\neg P\big(x, f(x)\big), Q\big(x, g(x)\big)\Big), \Big(\neg P\big(y, f(y)\big), \neg R\big(y, g(y)\big)\Big)\bigg\} \tag{8}
      $$
   
9. 利用归结反演方法来==**证明定理**==的具体步骤为：

   1. 否定目标公式 $G$，得到 $\neg G$；
   2. 将 $\neg G$ 并入到公式集 $F_1 \wedge F_2 \wedge \ldots \wedge F_n$ 中；
   3. 将公式集化子句集，得到子句集 $S$；
   4. 对 $S$ 进行归结，每次归结的结果并入到 $S$ 中。如此反复，直到得到空子句为止。此时，就证明了在前提 $F_1 \wedge F_2 \wedge \ldots \wedge F_n$ 为真时，结论 $G$ 为真。

10. 利用归结推理**==求解问题==**的具体步骤：

   1. 已知前提 $ F $ 用谓词公式表示，并化为子句集 $ S $；

   2. 把待求解的问题 $ P $ 用谓词公式表示，并否定 $ P $，再与 $ answer $ 构成析取式 $ (\neg P \lor answer) $；

   3. 把 $ (\neg P \lor answer) $ 化为子句集，并入到子句集 $ S $ 中，得到子句集 $ S' $；

   4. 对 $ S' $ 应用归结原理进行归结；

   5. 若得到归结式 $ answer $，则答案就在 $ answer $ 中。

10. 支持集策略：

    - 每次归结时，两个亲本子句中至少要有一个是目标公式否定的子句或其后裔。
    - 支持集 = 目标公式否定的子句集合 $\cup$ 这些子句通过归结生成的所有后裔子句

    特点：

    - 尽量避免在可满足的子句集中做归结，因为从中导不出空子句。而求证公式的前提通常是一致的，所以支持集策略要求归结时从目标公式否定的子句出发进行归结。支持集策略实际是一种目标制导的反向推理。
    - 支持集策略是完备的。

****

#### 归结推理的完备性证明

$\text{S is unsatisfiable} \Rightarrow S \vdash ()$

证明：（数学归纳法）

定义 $P(i)$ 表示：当 S 中含有 $i$ 个 literals 时，$\text{S 不可满足} \Rightarrow S \vdash ()$

1. 当 $i = 1$ 时，P(1) 是成立的。

   当 S 是含有 1 个 literal 的子句集时，不妨设含有的 literal 为 P

   $\because$ S 不可满足

   $\therefore$ S 只可能为 ${(P), (¬P)}$

   $\because$ $(P)$ 与 $(¬P)$ 可归结出 $()$

   $\therefore$ $S \vdash ()$

2. 假设：对于 $1 \le i \le k$，$P(i)$ 都成立

   $\because$ S 是含有 $k+1$ 个文字的子句集合，且 S 不可满足。

   从 S 中选取任意 literal，设选取的 literal 为 P。将 S 分为下列 3 个集合：

   * $S_p$：所有含有 P 的子句集
   * $S_{(\neg P)}$：所有含有 $\neg P$ 的子句集
   * $R$：所有不含 $P$ 或 $\neg P$ 的子句集

   $\therefore$ $R$ 是含有 $k$ 个 literal 的 S 的子句集

   情形 1：若 $R$ 不可满足

   $\because$ $P(k)$ 成立。

   $\therefore R \vdash ()$

   $\because R \subseteq S$

   $\therefore S \vdash ()$，即 $P(k + 1)$ 成立

   情形 2：若 R 可满足，即存在解释 $\widetilde{S}$ 使得 R 中的子句全为真。

   $\because$ S 整体不可满足

   $\therefore S_p, S_{(\neg P)}$ 中存在子句使得任意解释下都不满足

   * 若 $S_p$ 为空集，则取解释 $\widetilde{S}$ 并加上 $P$ 的取值为假，$S$ 便可满足。
   * 若 $S_{(\neg P)}$ 为空集，则取解释 $\widetilde{S}$ 并加上 $P$ 的取值为真，$S$ 便可满足。

   $\therefore S_p, S_{(\neg P)}$ 均不能为空集

   $\therefore$ 存在子句 $(P, \alpha)$ 和 $(\neg P, \beta)$ 使得 $P$ 无论取何值，$S$ 都不可满足。这里 $\alpha$ 和 $\beta$ 表示子句中其它不是 $P$ 的 literal

   $\because$ $(P, \alpha)$ 和 $(\neg P, \beta)$ 不论 $P$ 取何值均不能同时满足

   $\therefore$ 在 $\widetilde{S}$ 解释下，$\alpha$ 为假，$\beta$ 为假

   $\because$ $(P, \alpha)$ 和 $(\neg P, \beta)$ 可归结出 $(\alpha, \beta)$，而 $(\alpha, \beta)$ 在解释 $\widetilde{S}$ 下无法满足。令 $ R' = \{\alpha, \beta\} \cup R $

   $\therefore$ $ R' $ 无法满足，且只含有 $ k $ 个 literal

   $\because$ $ P(k) $ 成立

   $\therefore R' \vdash ( ) $，即 $ R' $ 中存在子句可归结出 ( )

   $\because R'$ 中的子句是属于 $ S $ 或由 $ S $ 中子句归结得到

   $\therefore S \vdash ()$ 即 $ P(k+1) $ 成立

****

#### 易错点

1. 判断对错：如果 $ S \models C $，那么 $ S \vdash C $。（错）

   例如：$ P \models (P, Q) $ 成立，但是 $ P $ 不能归结推导出 $ (P, Q) $

## 搜索技术

搜索的性质：

* 完备性：搜索算法是否总能在问题存在解的情况下找到解
* 最优性：当问题中的动作是需要成本时，搜索算法是否首先找到成本最小的解
* 时间复杂度：搜索算法最多需要探索/生成多少个节点来找到解
* 空间复杂度：搜索算法最多需要将多少个节点储存在内存中

****

### 盲目搜索

定义：这些策略都采用固定的规则来选择下一需要被扩展的状态；这些规则不会随着要搜索解决的问题的变化而变化；这些策略不考虑任何与要解决的问题领域相关的信息

| 标准 | 深度优先   | 宽度优先       | 深度受限   | 迭代加深   | 一致代价           |
| ---- | ---------- | -------------- | ---------- | ---------- | ------------------ |
| 时间 | $ O(b^m) $ | $ O(b^{d+1}) $ | $ O(b^L) $ | $ O(b^d) $ | $ O(b^{C^*/s+1}) $ |
| 空间 | $ O(bm) $  | $ O(b^{d+1}) $ | $ O(bL) $  | $ O(bd) $  | $ O(b^{C^*/s+1}) $ |
| 最优 | 否         | 是             | 否         | 是         | 是                 |
| 完备 | 否         | 是             | 否         | 是         | 是                 |

* $ b $：问题中一个状态最大的后继状态个数
* $ d $：是最短解的动作个数
* $ m $：是遍历过程中最长路径的长度
* $ L $：为限制的搜索深度
* $ C^* $ 为最优解的成本
* $ s $ 为动作的成本下界

****

#### 宽度优先搜索

定义：把当前要扩展的状态的后继状态放在边界的最后

性质：完备性、最优性

- 短的路径会在任何比它长的路径之前被遍历
- 给定路径长度，该长度的路径是有限的
- 最终可以遍历所有长度为 $ d $ 的路径，因此一定可以找出最短的解

时间复杂度：$ 1 + b + b^2 + \ldots + b^d + b(b^d - 1) = O(b^{d+1}) $

空间复杂度：$ b(b^d - 1) = O(b^{d+1}) $

* b = 问题中一个状态最大的后继状态个数，d = 最短解的动作个数

![image-20250401171257141](Note_img/image-20250401171257141.png)

#### 深度优先搜索

定义：把当前要扩展的状态的后继状态放在边界的最前面，边界上总是扩展最深的那个节点

完备性：

- 在状态空间无限的情况下：No
- 在状态空间有限，但是存在无限的路径（例如存在回路）的情况下：No
- 在状态空间有限，且对重复路径进行剪枝的情况下：Yes

最优性：No

时间复杂度：$ 1 + b + b^2 + \ldots + b^m - b = O(b^m) $

* 其中 $ m $ 是遍历过程中最长路径的长度，当 $ m $ 远远大于 $ d $ 时，时间效率会很差；当存在多条解路径的情况下深度优先搜索可能比宽度优先搜索更快找到解

空间复杂度：$ (b-1) + (b-1) + \ldots + (b-1) + b = bm - (m-1) = O(bm) $

* 深度优先回溯点 = 当前路径上的点的未扩展过的兄弟节点，一次只会考虑一条路径，边界上只包含当前探索的最深的节点，以及回溯点
* 线性复杂度是深度优先搜索一个显著的优点

![image-20250401172024336](Note_img/image-20250401172024336.png)

#### 一致代价搜索

定义：边界中，按路径的成本升序排列；总是扩展成本**最低**的那条路径

* 当每种动作的成本是一样的时候，和宽度优先是一样的

性质：完备性、最优性

- 一致代价搜索中，所有成本较低的路径都会在成本高的路径之前被扩展
- 给定成本，该成本的路径数量是有限的
- 成本小于最优路径的路径数量是有限的

时间复杂度和空间复杂度：$ O(b^{C^*/s+1}) $

* $ C^* $：最优解的成本
* 假设每个动作的成本 $ \geq s > 0 $
* 当最优解的路径长度为 $ d $ 时，宽度优先搜索的时间和空间复杂度都是 $ O(b^{d+1}) $。由此类比出一致代价搜索的时空复杂度

与BFS的区别：

- BFS按"层"（节点深度）扩展，UCS按路径成本扩展
- BFS假设所有边成本相同，UCS处理不同成本的边
- BFS使用普通队列，UCS使用优先队列（按成本）

#### 深度受限搜索

定义：深度优先搜索，但是预先限制了搜索的深度 $ L $，因此无限长度的路径不会导致深度优先搜索无法停止的问题。但只有当解路径的长度 $ \leq L $ 时，才能找到解

完备性：No

最优性：No

时间复杂度：$ O(b^L) $

空间复杂度：$ O(bL) $

* $ L $ 为限制的最大深度

#### 迭代加深搜索

定义：一开始设置深度限制为 $ L = 0 $，我们迭代地增加深度限制，对于每个深度限制都进行深度受限搜索。如果找到解，或者深度受限搜索没有节点可以扩展的时候可以停止当前迭代，并提高深度限制 $ L $。如果没有节点可以被剪掉（深度限制不能再提高）仍然没有找到解，那么说明已经搜索所有路径，因此这个搜索不存在解

完备性：Yes

最优性：Yes（在每个动作的成本一致的情况下）

* 如果动作成本不一致，则可以使用成本边界代替深度限制 $ L $：

  - 只扩展成本低于成本边界的路径

  - 每次迭代时记录当前还未扩展路径中的最小成本
  - 下一次迭代则提高成本边界

  这样开销会很大，迭代数量为成本数值的构成的集合的大小

时间复杂度：$ (d + 1)b^0 + db + (d - 1)b^2 + \ldots + b^d = O(b^d) $

空间复杂度：$ O(bd) $  

特点：迭代加深搜索可以比宽度优先搜索更高效：不用扩展深度限制上的节点。但是宽度优先搜索需要扩展直到目标节点。

### 启发式搜索

启发式函数 $h(n)$：估计从节点 $n$ 到达目标节点的成本

* 对于所有满足目标条件的节点 $n$，$h(n) = 0$

评价函数 $f(n) = g(n) + h(n)$

* $g(n)$：从初始节点到达节点 $n$ 的路径成本
* $f(n)$ 是经过节点 $n$ 从初始节点到达目标节点的路径成本的估计值

****

#### A 搜索

定义：利用节点对应的 $f(n)$ 值来对边界上的节点进行排序，并总扩展边界中具有最小 $f$ 值的节点。

启发函数的上限问题：

<img src="Note_img/image-20250402003130343.png" alt="image-20250402003130343" style="zoom:50%;" />

* $h(A)$ 的估计太大，甚至超出了实际的cost；过大的启发值淹没实际代价 $g(n)$，使得搜索脱离实际；因此启发式函数应该有上限

令 $ f(n) = g(n) + h(n) $ 和 $ f^*(n) = g^*(n) + h^*(n) $（最优路径代价）
$$
\begin{cases}
f(n) \leq f^*(n) \text{ (使得} n \text{点有被扩展的可能性)} \\
g^*(n) \approx g(n) \text{ (逐步优化得到的)}
\end{cases}
$$
可以得出：$ h(n) \leq h^*(n) $

- $ h(n) = 0 $ 退化为一致代价搜索，则可找到最优解，$ h(n) $ 趋于无穷则算法失效
- 如果 $ h(n) $ 高估了实际成本 $ h^*(n) $：这意味着算法可能会认为通过节点 $ n $ 的路径比实际上更糟，从而可能错过最短路径。因为如果 $ h(n) $ 过大，$ f(n) $ 也会相应变大，导致算法倾向于探索其他看似更有希望（即 $ f $ 值更小）的路径，而这些路径可能并不是最优的。
- 如果 $ h(n) $ 精确或低于实际成本 $ h^*(n) $：这样算法就不会错过任何潜在的最短路径，因为它总是偏向于探索那些估计总成本更低的路径。即使 $ h(n) $ 低估了，最坏的结果就是算法会探索更多节点，这可能会使搜索过程更慢，但仍然可以保证找到最优路径。

##### 用A解决八数码问题

![image-20250606211847746](C:\Users\19912\Desktop\Artificial-Intelligence\Note.assets\image-20250606211847746.png)

明确：

1. g是层数
2. h是与目标的区别数（当然也可以定义为曼哈顿距离和）
3. f是g+h

开始：

1. 初始化open表为开始状态
2. 初始化closed表为空
3. 从open表拿头节点（检查一下结束没）塞进close
4. 拓展头节点的所有子节点，优先队列写进open表，循环3
5. 如果open表为空，说明没有解，结束

#### A*搜索

定义：$h(n)$ 是可采纳的 A 算法（在A算法的基础上限定了启发式函数的选取）

时间复杂度和空间复杂度：$ O(b^{C^*/s+1}) $

* 最坏情况下时空复杂度和一致代价搜索一样，但是高效的启发式函数可以大幅度提升性能

$h(n)$ 的可采纳性：对于所有节点 $n$, 满足 $h(n) \le h^*(n)$，则 $h(n)$ 是可采纳的（比如说，衡量两个点之间的路程，你可以用直线距离，因为直线距离肯定小于路程；而曼哈顿距离则不一定了）

$h(n)$ 的一致性（单调性）：对于任意节点 $n_1$ 和 $n_2$，若 $h(n_1) \le c(n_1 \rightarrow n_2) + h(n_2)$，则 $h(n)$ 具有 一致性/单调性

* 对 $h(n_1) \le c(n_1 \rightarrow n_2) + h(n_2)$ 左右两边加 $g(n_1)$，得 $g(n_1) + h(n_1) \le g(n_1) + c(n_1 \rightarrow n_2) + h(n_2) \Rightarrow g(n_1) + h(n_1) \le g(n_2) + h(n_2) \Rightarrow f(n_1) \le f(n_2)$
* 如果变成 $\gt$，意味着高估。因为如果假设 $h(n_2) \approx h^*(n_2)$，则 $h(n_1) \gt c(n_1 \rightarrow n_2) + h^*(n_2) = h^*(n_1)$

从 *n* 到目标的估计代价 h*(*n*)，不能超过从 n* 到 *n*′ 的实际移动代价 c*(*n*,*n*′) 加上 *n*′ 的估计代价 h*(*n*′)。也就是说，**启发式估计不能“突然变小”**，否则会导致A*需要重新调整已探索的路径

可采纳性意味着最优性：最优解一定会在所有成本大于 $C^*$ 的路径之前被扩展到

* $C^*$ 为最优解成本

* 证明：

  > 假设 $ p^* $ 是一个最优解的路径；$ p $ 是一条满足 $ c(p) > c(p^*) $ 的路径，而且路径 $ p $ 在 $ p^* $ 之前被扩展。
  >
  > 那么扩展到路径 $ p $ 时，肯定会有一个 $ p^* $ 上的节点 $ n $ 处在边界上
  >
  > 因为 $ p $ 在 $ p^* $ 之前被扩展，则对于 $ p $ 路径上的最后那个节点（假设为目标节点）$ x $ 满足：$ f(x) \leq f(n) $。
  >
  > 因此 $c(p) = f(x) \leq f(n) = g(n) + h(n) \leq g(n) + h^*(n) = c(p^*)$
  >
  > 和 $ c(p) > c(p^*) $ 相矛盾

* 

满足一致性的启发式函数也一定满足可采纳性

* 证明：

  > Case 1: 从节点 $ n $ 没有路径到达目标节点，则可采纳性一定成立
  >
  > Case 2: 假设 $ n = n_1 \rightarrow n_2 \rightarrow \ldots \rightarrow n_k $ 是从节点 $ n $ 到目标节点的一条最优路径。可以使用数学归纳法证明对于所有的 $ i $，$ h(n_i) \leq h^*(n_i) $。
  >
  > Base: $ h(n_k) = 0 $
  >
  > Induction: $ h(n_{i-1}) \leq c(n_i) + h(n_i) \rightarrow h(n_i) \leq c(n_{i-1} \rightarrow n_i) + h^*(n_i) = h^*(n_{i-1}) $

环检测的影响：如果启发式函数只有可采纳性，不一定能在使用了环检测之后仍保持最优性

<img src="Note_img/image-20250402231122962.png" alt="image-20250402231122962" style="zoom:50%;" />

问题：对于一致代价搜索，使用环检测后是否具有最优性？

答案：否，反例如上图（不看h即可）

若启发式函数具备单调性，就能在进行环检测之后仍然保持最优性

* 证明：分为三个命题逐步证明

  命题1：一条路径上的节点的 $f$ 函数值是非递减的

  > $\because h(n_1) \le c(n_1 \rightarrow n_2) + h(n_2)$
  >
  > $\therefore g(n_1) + h(n_1) \le g(n_1) + c(n_1 \rightarrow n_2) + h(n_2)$
  >
  > $\therefore g(n_1) + h(n_1) \le g(n_2) + h(n_2)$
  >
  > $\therefore f(n_1) \le f(n_2)$

  命题2：如果节点 $n_2$​ 在节点 $n_1$ 之后被扩展，则有 $f(n_1) \le f(n_2)$

  命题3：使用单调的启发式函数的 $A^*$ 搜索在第一次扩展到某个状态，就是沿着最小成本的路径进行扩展的

  > 假设路径 $p = n_1 \rightarrow n_2 \ldots \rightarrow n_k = n$ 是第一条被发现的到达 $n$ 的路径
  >
  > 假设路径 $p_j = m_1 \rightarrow m_2 \ldots \rightarrow m_j = n$ 是第二条被发现的到达 $n$ 的路径
  >
  > 假设 $c(p)$ 是通过 $p$ 路径到达 $n$ 节点的成本
  >
  > 假设 $c(p_j)$ 是通过 $p_j$ 路径到达 $n$ 节点的成本
  >
  > 根据命题2，$c(p) + h(n) \leq c(p_j) + h(n)$
  >
  > 因此 $c(p) \leq c(p_j)$

#### IDA*

A*搜索和宽度优先搜索或一致代价搜索一样，也存在潜在的空间复杂度过大的问题。

``IDA*``（迭代加深的 ``A*`` 搜索）：用于解决空间复杂度过大的问题，它类似于迭代加深算法，但是IDA*用于划定界限的不是深度，而是 $ f $ 值，即 $ g + h $ 。

在每次迭代时，IDA* 划定的界限是 $ f $ 值超过上次迭代的界限最少的节点的 $ f $ 值。

### 课本例题

#### 八数码

#### 积木世界

#### 传教士野蛮人

## 机器学习

### 朴素贝叶斯

**条件独立性**：从联合概率的角度来表示，在 A 的条件下 B 与 C 条件独立：
$$
p(B, C|A) = p(B|A)p(C|A)
$$

* 在给定 A 的条件下 B 与 C 条件独立，则 $ p(B|A \cap C) = p(B|A) $

  > 证明：
  > $$
  > \because p(B, C|A) = p(B|A)p(C|A) \\[4pt]
  > \therefore \frac{p(ABC)}{P(A)} = \frac{p(AB)}{p(A)} \cdot \frac{p(AC)}{p(A)} \\[4pt]
  > \therefore \frac{p(ABC)}{P(AC)} = \frac{p(AB)}{p(A)} \cdot \frac{p(A)}{p(A)} \\[4pt]
  > \therefore  p(B|A \cap C) = p(B|A)
  > $$

  从这个角度看，条件独立性的本质是：一旦我们知道了 $ B $ 的值，额外知道 $ C $ 对 $ A $ 的概率没有影响。

- 条件独立性指的是在条件概率空间 $ p(\cdot|A) $ 中的独立性。

**贝叶斯推断的含义**：

* 对条件概率或者说乘法公式变形得：
  $$
  P(A|B) = P(A) \frac{P(B|A)}{P(B)}
  $$

  * $P(A)$ 称为先验概率，即在 $B$ 事件发生之前，对A 事件概率的一个判断。

  * $P(A|B)$ 称为后验概率，即在 $B$ 事件发生之后，我们对A 事件概率的重新评估。

  * $\frac {P(B|A)}{P(B)}$ 称为可能性函数，这是一个调整因子，使得预估概率更接近真实概率。

* 因此贝叶斯推断可理解为：
  $$
  \text{后验概率} = \text{先验概率} \times \text{调整因子}
  $$
  贝叶斯推断含义：我们先预估一个先验概率，然后加入实验结果，看这个实验到底是增强还是削弱了先验概率，由此得到更接近事实的后验概率。（**利用新证据（数据）来调整我们原有的（先验）概率，得到更新后的（后验）概率**。）

**贝叶斯分类器原理推导**：

* 假设一个输入事件有属性 $ (A_1, A_2, \cdots, A_n) $，要按照属性分类到 $(C1, C_2, \cdots, C_m)$ 中的一个，就是要找到使 $ P(C_j | A_1, A_2, \ldots, A_n) $ 最大化的 $C_j$

  使用贝叶斯定理计算所有 $C$ 值的后验概率：
  $$
  P(C | A_1 A_2 \cdots A_n) = \frac{P(A_1 A_2 \cdots A_n | C) P(C)}{P(A_1 A_2 \cdots A_n)}
  $$
  选择使 $ P(C | A_1, A_2, \ldots, A_n) $ 最大化的 $C$ 值，等价于选择使 $ P(A_1, A_2, \ldots, A_n | C) P(C) $ 最大化的 $C$ 值。

  假设在给定类别 $C_j$ 的情况下，属性 $ A_i $ 之间是相互独立的，则有：
  $$
  P(A_1, A_2, \ldots, A_n | C_j) = P(A_1 | C_j) P(A_2 | C_j) \ldots P(A_n | C_j)
  $$
  可以估计所有 $ A_i $ 和 $ C_j $ 的 $ P(A_i | C_j) $，则简化了计算。如果 $\forall j \in m$，如果 $P(C_j) P(A_1 | C_j) P(A_2 | C_j) \ldots P(A_n | C_j) $ 最大，则该事件被分类为 $ C_j $。

**做题**：

1. 计算训练样本结果中每个分类出现的概率 $ P(C_j) $
2. 计算每个属性在每个分类下的条件概率 $ P(A_i | C_j) $
3. 对给出要你分类的新样本的属性，   计算每个分类的后验概率 $ P(C_j | A_1, A_2, \ldots, A_n) = P(C_j) P(A_1 | C_j) P(A_2 | C_j) \ldots P(A_n | C_j) $
4. 大的那个就是分类结果

**连续属性的处理**

* 示例：

  <img src="Note_img/image-20250523101616068.png" alt="image-20250523101616068" style="zoom:67%;" />

  测试数据：（男性，低风险地区，阴性，77kg）

  1. 离散化：将范围划分为区间

     * 大区间数量：训练记录太少，难以可靠估计
     * 小区间数量：会将不同类别的记录合并在一起

  2. 概率密度估计

     用概率密度近似条件概率。假设符合正态分布：
     $$
     P(A_i|C_j) = \frac{1}{\sqrt{2\pi\sigma_{ij}^2}} e^{-\frac{(A_i-\mu_{ij})^2}{2\sigma_{ij}^2}}
     $$
     比如，对于（A4, C = 未感染），统计得到其均值与方差

     * 均值 mean = 67
     * 方差 variance = 104

     $ P(A4 = 77|未感染) = \frac{1}{\sqrt{2\pi \times 104}} e^{-\frac{(77-67)^2}{2 \times 104}} = 0.0245 $

**平滑化**：由于样本数量的缺失，部分条件概率会出现0值，此时可基于概率估计方法进行平滑化。
$$
\text{Original}: P(A_i|C) = \frac{N_{ic}}{N_c}	\\

\text{Laplace}: P(A_i|C) = \frac{N_{ic} + 1}{N_c + c}
$$

- $ N_{ic} $：类别为 $ c $ 且属性为 $ A_i $ 的样本数
- $ N_c $：类别 $ c $ 的样本数
- $ c $：类别数量

平滑技术可以避免模型过度依赖训练数据，尤其在数据稀疏的情况下，通过给未见过的特征值分配适度的概率，提升模型的鲁棒性。

**贝叶斯网络**：把某个研究系统中涉及的随机变量，根据是否条件独立绘制在一个有向图中，就形成了贝叶斯网络。其主要用来描述随机变量之间的条件依赖，用圈表示随机变量，用箭头表示条件依赖。

举个例子：

![image-20250523103650359](Note_img/image-20250523103650359.png)

如果你了解到 E、C、A 或 B 中的任何一个，你对 $ p(H) $ 的评估将会改变。例如，如果这些中的任何一个被认为为真，你将增加 $ p(h) $ 并减少 $ p(\neg h) $。因此，H 不独立于 E、C、A 或 B。但是，如果你知道了 B 的值（真或假），了解 E、C 或 A 的值不会影响 $ p(H) $。这些因素对 H 的影响是通过它们对 B 的影响来调节的。因此，在给定 B 的情况下，H 独立于 E、C 和 A。

这意味着：

- $ p(H|B, \{A, C, E\}) = p(H|B) $
- $ p(B|A, \{C, E\}) = p(B|A) $
- $ p(A|C, \{E\}) = p(A|C) $

<img src="Note_img/image-20250523105252753.png" alt="image-20250523105252753"  />

因此，$ P(H, B, A, C, E) = P(H|B) P(B|A) P(A|C) P(C|E) P(E) $，这只需要 $2 + 2 + 2 + 2 + 1 = 9$ 个参数

相比之下，$ P(H, B, A, C, E) = P(H|B, A, C, E) P(B|A, C, E) P(A|C, E) P(C|E) P(E) $ 需要 $2^4 + 2^3 + 2^2 + 2 + 1 = 31$ 个参数。

贝叶斯网络示例：

<img src="Note_img/image-20250523105700569.png" alt="image-20250523105700569" style="zoom:50%;" />

**贝叶斯网络 D-分离**

以下面的 BN 为例：

<img src="Note_img/image-20250523112423010.png" alt="image-20250523112423010" style="zoom:50%;" />

1. 链式结构：

   <img src="Note_img/image-20250523112454148.png" alt="image-20250523112454148" style="zoom:50%;" />

   **在给定 A 的前提下，M 与 B 条件独立**

   > 证明：
   > $$
   > \begin{align}
   > P(M|A, B) &= \frac{P(M, A, B)}{P(A, B)} \\ 
   > &= \frac{P(M, A, B, \sim E) + P(M, A, B, E)}{P(A, B, \sim E) + P(A, B, E)} \\
   > &= \frac{P(B) P(\sim E) P(A | B, \sim E) P(M | A) + P(B) P(E) P(A | B, E) P(M | A)}{P(B) P(\sim E) P(A | B, \sim E) + P(B) P(E) P(A | B, E)} \\
   > &= P(M | A)
   > \end{align}
   > $$

2. 分叉结构

   <img src="Note_img/image-20250523113553628.png" alt="image-20250523113553628" style="zoom:50%;" />

   1. **在给定 A 的前提下，J 与 M 条件独立**

      > 证明：
      > $$
      > \begin{align}
      > P(J, M|A) &= \frac {P(J, M, A)}{P(A)} \\
      > &= \frac{P(A) P(J | A) P(M | A)}{P(A)} \\
      > &= P(J | A) P(M | A)
      > \end{align}
      > $$

   2. **在不给定 A 的前提下，J 与 M 不独立**

      > 证明：
      > $$
      > \begin{align}
      > P(M) &= P(M | A) P(A) + P(M | \sim A) P(\sim A) \\[5pt]
      > P(M | J) &= \frac{P(M, J)}{P(J)} \\
      > &= \frac{P(M, J, \sim A) + P(M, J, A)}{P(J) = P(J | A) P(A) + P(J | \sim A) P(\sim A)} \\
      > \end{align}
      > $$
      > $$
      > \because P(A) = 0.002516 \\
      > \therefore P(M) = 0.011736 \ne P(M|J) = 0.039972
      > $$

3. 对撞结构

   <img src="Note_img/image-20250523114549059.png" alt="image-20250523114549059" style="zoom:50%;" />

   1. **在给定 A 的前提下，B 与 E 不条件独立**

      > 证明：
      > $$
      > \begin{align}
      > P(B|A) &= \frac{P(A, B)}{P(A)} \\
      > &= \frac{P(A, B, E) + P(A, B, \sim E)}{P(A)} \\
      > P(B|A, E) &= \frac{P(A, B, E)}{P(A, E)} \\
      > &= \frac{P(A, B, E)}{P(A, B, E) + P(A, \sim B, E)}
      > \end{align}
      > $$
      > $$
      > \begin{align}
      > \because P(A) &= 0.0025164 \\
      > P(A, B, E) &= P(B)P(E)P(A|B, E) \\ &= 0.001 * 0.002 * 0.95 = 0.0000019 \\
      > P(A, B, \sim E) &= P(B)P(\sim E)P(A|B, \sim E) \\
      > &= 0.001 * 0.998 * 0.94 = 0.00093812 \\
      > P(A, \sim B, E) &= P(\sim B) P(E) P(A|\sim B, E) \\
      > &= 0.999 * 0.002 * 0.29 = 0.00057942 \\
      > \therefore P(B|A) &= \frac{0.0000019 + 0.00093812}{0.0025164} = 0.374 \\
      > P(B|A, E) &= \frac{0.0000019}{0.0000019 + 0.00057942} = 0.003268
      > \end{align}
      > $$
   
   2. **在未给定 A 的前提下，B 与 E 是独立的**
   
      > 证明：
      > $$
      > \begin{align}
      > P(B|E) &= \frac{P(B, E)}{P(E)} \\
      > &= \frac{P(B) P(E)}{P(E)} = P(B)
      > \end{align}
      > $$
   
4. D-分离：

   定义：路径 $ p $ 被限定集 $ Z $ 阻塞当且仅当：
   - 路径 $ p $ 含有链式结构 $ A \rightarrow B \rightarrow C $ 且节点 $ B $ 在 $ Z $ 中，或者
   - 路劲 $p$ 含有分叉结构 $ A \leftarrow B \rightarrow C $ 且中间节点 $ B $ 在 $ Z $ 中，或者
   - 路径 $ p $ 含有对撞结构 $ A \rightarrow B \leftarrow C $ 且对撞节点 $ B $ ==**及其后代**==都不在 $ Z $ 中。

   定义：若 $ Z $ 阻塞了节点 $ X $ 和节点 $ Y $ 之间的==每一条==路径，则称给定 $ Z $ 时，$ X $ 和 $ Y $ 是 D-分离的，即给定 $ Z $ 时，$ X $ 和 $ Y $ 条件独立。

5. 示例：

   <img src="Note_img/image-20250523211117526.png" alt="image-20250523211117526" style="zoom:50%;" />

   * $R \perp B$：路径 `R-T-B`，T 阻塞，独立
   * $R \perp B | T$：路径 `R-T-B` 活跃（因为 T 给出），不独立
   * $R \perp B|T^{'}$：路径 `R-T-B` 活跃（因为 T 的后代给出），不独立

   <img src="Note_img/image-20250523211746811.png" alt="image-20250523211746811" style="zoom:50%;" />

   * $L \perp T^{'}|T$：路径 `L-r-T-T'`，T 阻塞，独立
   * $L \perp B$：路径 `L-R-T-B`，R、T 阻塞，独立
   * $L \perp B|T$：路径 ？？？？？？

   <img src="Note_img/image-20250523212135734.png" alt="image-20250523212135734" style="zoom:50%;" />

### K-means

**K-means 的算法步骤为：**

1. 选择初始化的 $k$ 个样本作为初始聚类中心 $a = a_1, a_2, \cdots a_k$ ；
2. 针对数据集中每个样本 $x_i$ 计算它到 $k$ 个聚类中心的距离并将其**分到**距离最小的聚类中心所对应的类中；
3. 针对每个类别 $a_j$ ，重新计算它的聚类中心 $a_j = \frac{1}{|c_i|} \sum_{x \in c_i} x$ （即属于该类的所有样本的质心）；
4. 重复上面 2 3 两步操作，直到达到某个中止条件（迭代次数、最小误差变化等）。

> * 初始质心通常是随机选择的。
>   * 每次运行产生的簇可能会有所不同。
> * 质心（通常）是簇中点的平均值。
> * “接近度”可以通过欧几里得距离、余弦相似度、相关性等来衡量。
> * K-means 对于上述提到的常见相似性度量会收敛。
> * 大多数收敛发生在最初的几次迭代中。
>   * 通常停止条件会改为“直到相对较少的点改变簇”。
> * 复杂度是 $O(nKld)$
>   * n = 点的数量，K = 簇的数量，l = 迭代次数，d = 属性的数量。

**K-means 的评估**

- 最常用的度量是平方误差和（SSE）
  $$
  SSE = \sum_{i = 1}^K \sum_{x \in C_i}dist^2(m_i, x)
  $$

  * $x$ 是簇 $C_i$ 中的一个数据点，$m_i$ 是簇 $C_i$ 的代表点（在上述公式中，$m_i$ 对应于簇的中心（均值））

- 减少SSE的一个简单方法是增加簇的数量 $K$
  - $K$ 值小的好聚类可能比 $K$ 高的差聚类具有更低的 $SSE$

**K 的选择**

- 肘部法则：为每个 *K* 值绘制 SSE 的折线图。如果折线图看起来像一个手臂，那么手臂上的“肘部”就是最佳的 *K* 值。

  ![image-20250509110534649](Note_img/image-20250509110534649.png)

**Bisecting K-means（二分聚类）**

1. 初始化：将所有数据点视为一个簇。
2. 分裂：从当前的簇中选择一个簇进行分裂。选择的标准通常是选择那些分裂后可以最大程度减少误差平方和（SSE）的簇。
3. 应用K-Means：对选定的簇应用标准的K-Means算法，将其分成两个簇。
4. 评估：检查是否达到了所需的聚类数目。如果没有，返回步骤2；如果达到了，算法结束。

**K-means 局限性**

1. 不同大小：

   <img src="Note_img/image-20250509112434211.png" alt="image-20250509112434211" style="zoom:50%;" />

2. 不同密度：

   <img src="Note_img/image-20250509112500166.png" alt="image-20250509112500166" style="zoom:50%;" />

3. 非球形

   <img src="Note_img/image-20250509112516565.png" alt="image-20250509112516565" style="zoom:50%;" />

**克服 K-means 局限性（K-means++）**

- 从**数据集**中随机选择第一个中心点 $x_1$

- 计算每个样本点到已有的最近的聚类中心的距离 $D(x)$，计算每个点被选中的概率
  $$
  \frac{D(x_i)^2}{\sum_{x_k \in X} D(x_k)^2}
  $$
  根据上述概率分布，通过轮盘赌法随机选择下一个中心点。

- 不断重复直到选定 $K$ 个簇

**K-means++ 局限性**

- 需要对数据进行 $K$ 次遍历
- 在大数据应用中，不仅数据量庞大，而且 $K$ 通常也很大。
- 无法扩展

### DBSCAN

在密度的定义下，DBSCAN算法将数据点分为三类：

- **核心点**：如果一个点的eps-邻域内包含至少minPts数目的点，它就是一个核心点。
- **边界点**：如果一个点不是核心点，但在某个核心点的eps-邻域内，则该点是边界点。
- **噪声点**：既不是核心点也不是边界点的点被视为噪声点。

**DBSCAN 算法**：

1. 将所有点标记为核心点、边界点或噪声点。
2. 消除噪声点。
3. 在所有在Eps范围内的核心点之间建立边。
4. 将每组连接的核心点组成一个独立的簇。
5. 将每个边界点分配给其关联的核心点所属的簇之一。

**DBSCAN 优点**

* 抗噪声能力强
* 可以处理不同形状和大小的簇

**DBSCAN 不擅长的情况**

* 不同密度
* 高纬度数据

**DBSCAN 和 K-MEANS的比较**

|                      |            K-means             |                  DBSCAN                  |
| :------------------: | :----------------------------: | :--------------------------------------: |
|       聚类对象       |            所有对象            |                 剔除噪声                 |
|         类型         |         基于原型的聚类         |              基于密度的聚类              |
| 密度差异大时表现不佳 | 难以处理非球形簇和不同大小的簇 | 能够处理不同大小和形状的簇，不受噪声影响 |
|       定义需求       |        需要明确的中心点        |      需要定义密度（eps 和 minPts）       |
|     稀疏高维数据     |            表现良好            |    使用欧几里得距离定义密度时表现较差    |
|     数据分布假设     |        假设球形高斯分布        |     无假设，能处理不同形状和大小的簇     |
|       噪声处理       | 对噪声敏感，可能影响中心点计算 | 能有效处理噪声，边界点和噪声点可明确区分 |
|        簇数量        |            用户定义            |                 自动生成                 |

**评价簇的内部指标：凝聚度和分离度**

* 簇凝聚度：衡量簇内对象的紧密相关程度

  * SSE 组内平方和
    $$
    SSE = \sum_{i} \sum_{x \in C_i} (x - m_i)^2
    $$

* 簇分离度：衡量一个簇与其他簇的区分程度或分离程度

  * SSB：组间平方和
    $$
    SSB = \sum_i |C_i| (m - m_i)^2
    $$
    其中 $∣C_i∣$ 是簇 $i$ 的大小（包含数据点的数量），$m$ 是所有对象的中心（均值）

* $SSE + SSB = SST$（constant）

### 人工神经元模型（MP）

一个典型的神经元模型：包含有 N 个输入，1 个输出，以及 2 个计算功能，每个连接上有一个权值。

神经元的计算公式：用 $\mathbf{x} = [x_1, x_2, x_3]^T $ 表示输入，用 $ W = [w_1, w_2, w_3] $ 表示权值，经过加权计算末端信号为 $ W \cdot \mathbf{x} $，再叠加加非线性函数 $ g $，即是输出值 $ z $

- 在MP模型里，非线性函数 $ g $ 设置是符号函数（sign）
- 由于起到类似神经元的“激活”作用，非线性函数也称作激活函数（Active Function）

<img src="Note_img/image-20250509154942030.png" alt="image-20250509154942030" style="zoom:50%;" />

对神经元模型的图进行简化：将求和函数 sum 与激活函数 sign 合并到一个圆圈里，代表神经元的内部计算。此时，一个“节点”就是一个神经元。

<img src="Note_img/image-20250509155748102.png" alt="image-20250509155748102" style="zoom:50%;" />

1943年发布的MP模型，虽然简单，但已经建立了神经网络大厦的地基。然而，MP模型中，权重的值都是预先设置的，因此不能进行学习。

### MLP 模型

#### 感知机模型

感知机：两层神经元构成

* 输入层：在 MP 模型的输入位置添加神经元节点，只传输数据，不做计算
* 输出层：对前面一层的输入进行计算

感知机模型数学化：

- 输入向量 $\mathbf x = [x_1, x_2, x_3]^T $，输出向量 $\mathbf z = [z_1, z_2]^T $，系数矩阵 $ W \in \mathbb{R}^{2 \times 3} $
  $$
  z_1 = g(x_1 w_{1,1} + x_2 w_{1,2} + x_3 w_{1,3}) \\
  z_2 = g(x_1 w_{2,1} + x_2 w_{2,2} + x_3 w_{2,3})
  $$

- 则用矩阵乘法表达感知机的计算公式为：$\mathbf z = g(W \cdot x) $

<img src="Note_img/image-20250510161709170.png" alt="image-20250510161709170" style="zoom:50%;" />

感知机的权重通过训练获得：
$$
\text{对于所有} y \ne \hat y \text{ : } \min_{\mathbf w} - \sum y (\mathbf w \cdot \mathbf x) \\
\hat y = sign(\mathbf w \cdot \mathbf x)
$$

* $\mathbf w$ 是系数矩阵的一行（通俗讲就是：$\mathbf w$ 某一个输出神经元的所有权重）

  <img src="Note_img/image-20250510165823325.png" alt="image-20250510165823325" style="zoom:50%;" />

* $y \ne \hat y$ 代表只需考虑预测错误的的输出神经元

* 对于任一  $y \ne \hat y  \text{, } | \mathbf w \cdot \mathbf x |$ 是该错误输出值相较于正确输出值的误差。而：
  $$
  |\mathbf w \cdot \mathbf x| = - y (\mathbf w \cdot \mathbf x)
  $$

  * 当 $y = +1, \mathbf w \cdot \mathbf x < 0, - y (\mathbf w \cdot \mathbf x) = |\mathbf w \cdot \mathbf x|$
  * 当 $y = -1, \mathbf w \cdot \mathbf x > 0, - y (\mathbf w \cdot \mathbf x) = |\mathbf w \cdot \mathbf x|$

* 感知机的训练就是让误差变得尽可能小。而这里的误差变小可以视作：

  * 若真实值为 $+1$，$\mathbf w$ 和 $\mathbf x$ 的角度尽可能小（钝角的角度变小）
  * 若真是值为 $-1$，$\mathbf w$ 和 $\mathbf x$ 的角度尽可能大（锐角的角度变大）

因此感知机训练法制：
$$
W_t \leftarrow W_t + \Delta W_t \\
\Delta W_t = \eta y \mathbf x
$$

- $ y $：真实的目标
- $ \hat{y} $：感知机的输出
- $ \eta $：学习速率（如 0.1）
- $ x $：训练数据

<img src="Note_img/image-20250510164925232.png" alt="image-20250510164925232" style="zoom:50%;" />

感知机模型的数学几何意义：感知机模型可以试做 $n$ 维空间的决策超平面。

* 对系数矩阵 $W$，该超平面就是 $W \mathbf x = 0$

感知机模型的缺陷：只适用于线性分类任务。

#### 多层感知机（MLP）

多层感知机包含三个层次：一个输入层，一个或多个中间层 (也叫隐藏层，hidden layer) 和一个输出层。输入层与输出层的节点数是固定的，中间层则可以自由指定。

![image-20250510171543280](Note_img/image-20250510171543280.png)

MLP 数学化表达：使用向量和矩阵来表示神经网络中的变量。$ x, a, z $ 是网络中传输的向量数据。$ W_1 $ 和 $ W_2 $ 是网络的矩阵参数。MLP通常还会引入偏置单元，它与后一层的所有节点都有连接。

<img src="Note_img/image-20250510171919527.png" alt="image-20250510171919527" style="zoom: 33%;" />

MLP 模型的数学几何意义：

* 对于两层神经网络，系数矩阵 $W_1$ 和 $W_2$ 的复合会形成一个光滑的曲线（这实际上也是只能做线性分类问题，只不过从平面变成了曲面）。

  <img src="Note_img/image-20250510172318153.png" alt="image-20250510172318153" style="zoom:50%;" />

* 关键在于:  从输入层到隐藏层时，数据在激活函数作用下发生了空间扭曲（这使得数据的原始坐标空间从线性不可分，转换成了线性可分）

  <img src="Note_img/image-20250510172443385.png" alt="image-20250510172443385" style="zoom:60%;" />

训练多层感知机：

* 前向传播：计算当前参数下的误差。

  * 按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。

  * 每次计算，都需要经过线性加权求和、激活函数激活两个步骤。

    ![image-20250510173448382](Note_img/image-20250510173448382.png)

* 梯度下降：沿着梯度下降的方向更新参数，使得误差最小。

  每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。

  <img src="Note_img/image-20250510174245125.png" alt="image-20250510174245125" style="zoom: 33%;" />

  求导示例：一个具有两个输入、两个隐藏神经元和两个输出神经元的神经网络。考虑 $w_5$，探究 $w_5$ 的变化对总误差的影响有多大

  <img src="Note_img/image-20250510174734161.png" alt="image-20250510174734161" style="zoom: 33%;" />

  * 损失函数：
    $$
    E_{total} = \sum \frac{1}{2} (target_i - out_{oi})^2 \\[4pt]
    $$
    $$
    \begin{aligned}
    \frac{\partial E_{total}}{\partial out_{o1}} &= 2 * \frac{1}{2} (target_{o1} - out_{o1})^{2-1} * (-1) + 0 \\[2pt]
    &= - (target_{o1} - out_{o1}) \\[5pt]
    &= - (0.01 - 0.751365507) = 0.741365507 \\[5pt]
    \end{aligned}
    $$

  * 激活函数：
    $$
    \begin{aligned}
    out_{o1} = \frac{1}{1 + e^{-net_{o1}}} \\[4pt]
    \end{aligned}
    $$
    $$
    \begin{aligned}
    \frac{\partial out_{o1}}{\partial net_{o1}} &= out_{o1}(1 - out_{o1}) = 0.186815602\\[5pt]
    \end{aligned}
    $$

  * 线性求和：
    $$
    net_{o1} &= w_5 * h_1 + w_6 * h_2 + b_2 * 1 \\[6pt]
    $$
    $$
    \begin{aligned}
    \frac{\partial net_{o1}}{\partial w_5} &= 1 * h_1 * w_5^{(1-1)} + 0 + 0 \\
    &= h_1 = 0.5932699992 \\
    \end{aligned}
    $$

  * 参数更新：
    $$
    \text{设置学习率 } \eta = 0.5
    $$
    $$
    \begin{aligned}
    w_5^+ &= w_5 - \eta * \frac{\partial E_{total}}{\partial w_5} \\
    &= 0.4 - 0.5 * 0.082167041 \\[3pt]
    &= 0.35891648
    \end{aligned}
    $$


  继续反向传播 $w_1$：

  <img src="Note_img/image-20250511000903763.png" alt="image-20250511000903763" style="zoom:50%;" />

  <img src="Note_img/image-20250511001226597.png" alt="image-20250511001226597" style="zoom:50%;" />

  <img src="Note_img/image-20250511001303585.png" alt="image-20250511001303585" style="zoom:50%;" />

* 反向传播：根据误差调整参数

  反向传播算法不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。

MLP 缺陷：

1. 非凸模型优化问题存在局部最优解问题

2. 梯度衰减问题

   <img src="Note_img/image-20250511001605360.png" alt="image-20250511001605360" style="zoom: 50%;" />

   以 sigmoid 函数为例，$\sigma (x) = \frac{1}{1 + e^{-x}}$，而 $0 \le \frac{d}{dx} \sigma(x) = \sigma (x) \big(1 - \sigma (x)\big) \le 0.25$。在神经网络反向传播梯度时，每传递一层梯度衰减为原来的 0.25。层数一多，梯度指数衰减后低层基本上接受不到有效的训练信号。

激活函数：

1. **sigmoid**

   数学表达式为：
   $$
   sigmoid(x) = \frac{1}{1 + e^{-x}}
   $$
   求导表达式为：
   $$
   \frac{d(sigmoid(x))}{dx} = sigmoid(x)(1 - sigmoid(x))
   $$
   函数图像为

   ![image-20250511002658927](Note_img/image-20250511002658927.png)

2. **Tanh**

   数学表达式为：
   $$
   Tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
   $$
   函数图像如下：

   ![image-20250511002713085](Note_img/image-20250511002713085.png)

3. **ReLU**

   数学表达式为：
   $$
   ReLU(x) = max(0, x)
   $$
   函数图像如下：

   ![image-20250511002720796](Note_img/image-20250511002720796.png)

   Relu会使部分神经元的输出为0，造成了网络的稀疏性，减少了参数的相互依存关系，缓解过拟合问题的发生

4. **Softmax**

   数学表达式为：
   $$
   Softmax(x) = \frac{e^{x_i}}{\sum_i e^{x_i}}
   $$
   函数图像如下：

   ![image-20250511002728606](Note_img/image-20250511002728606.png)

损失函数：

1. **均方误差（MSE）**
   $$
   MSE = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat y_i)
   $$

2. **交叉熵（LCE）**
   $$
   LCE = -\sum_i^n \sum_j^k y_j^{(i)} \log {\hat y_j^{(i)}}
   $$

   * $y_j^{(i)}$ 是第 $j$ 个输入参数在第 $i$ 个输出的真实值。
   * $\hat y_j^{(i)}$ 是第 $j$ 个输入参数在第 $i$ 个输出的预测值。

分类任务评测指标：

1. **类别级指标**

   - **precision（精确率）**：预测为某类的样本中实际属于该类的比例。

     计算公式：
     $$
     Precision = \frac{TP}{TP + FP} \\
     $$

     * **TP (True Positive)**：正确预测为正类的样本数（预测为A类，实际也是A类）
     * **FP (False Positive)**：错误预测为正类的样本数（预测为A类，实际是其他类）
     * $TP + FP$：预测为正类的总预测数

   - **recall（召回率）**：实际属于某类的样本中被正确预测的比例。

     计算公式：
     $$
     Recall = \frac{TP}{TP + FN}
     $$

     * **TP (True Positive)**：正确预测为正类的样本数（预测为A类，实际也是A类）
     * **FN (False Negative)**：错误预测为负类的样本数（实际是A类，但被预测为其他类）

   - **f1-score**：精确率和召回率的调和平均，综合反映分类质量。

     计算公式：
     $$
     F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
     $$

2. **全局指标**

   - **accuracy**：整体正确分类比例

     计算公式：
     $$
     Accuracy = \frac{正确预测的样本数}{总样本数}
     $$

   - **macro avg**：各类别指标的算术平均

   - **weighted avg**：按样本量加权的平均指标

   由于各类指标同等重要，因此我们选择 accuracy 来作为性能的评价指标。

神经网络的过拟合：

<img src="Note_img/image-20250511003125943.png" alt="image-20250511003125943" style="zoom:33%;" />

### 决策树

#### CLS 算法

#### ID3 算法



## 深度学习

### 卷积神经网络

基于视觉机理的卷积神经网络：

1. 局部特征影响大

   <img src="Note_img/image-20250512092336439.png" alt="image-20250512092336439"  />

2. 重要位置常变化

   <img src="Note_img/image-20250512092415328.png" alt="image-20250512092415328" style="zoom:150%;" />

3. 采样压缩也没差

   <img src="Note_img/image-20250512092503611.png" alt="image-20250512092503611" style="zoom: 70%;" />

卷积核：一个小型的权重矩阵，其数值通过训练自动学习得到。

* 在输入数据上滑动，逐位置进行点乘求和运算，生成特征图。

  <img src="Note_img/image-20250512092807416.png" alt="image-20250512092807416" style="zoom: 67%;" />

特征图维度：
$$
高度~ h = \lfloor \frac{n_h - f + 2p}{s} + 1 \rfloor \\
宽度~ w = \lfloor \frac{n_w - f + 2p}{s} + 1 \rfloor \\
深度~ k = K
$$

* $n_h$：输入图片的高度

* $n_w$：输入图片的宽度

* $K$：卷积核个数

  <img src="Note_img/image-20250512102717326.png" alt="image-20250512102717326" style="zoom:67%;" />

池化：

* 池化操作都有一个固定的窗口，可以称为池化窗口，类似与卷积操作中的卷积核，表示选取的数据范围。

* 最大池化：每次选取移动框内数的最大值

  <img src="Note_img/9a4237da2270164ba32259ec9696d81f.gif" alt="img" style="zoom: 67%;" />

* 池化的作用：有效的缩小参数矩阵的尺寸，从而减少最后连接层的中的参数数量，加快计算速度和防止过拟合。

卷积核的优势：

1. 可以识别局部特征
2. 可以识别不同区域的相似特征
2. 减少参数量
2. 共享权重

### 循环神经网络

独热码：用向量表示单词

* 示例：
  $$
  \text{词典} = \{apple, bag, cat, dog, elephant\} \\
  
  \begin{align*}
  apple &= [1 \ 0 \ 0 \ 0 \ 0] \\
  bag &= [0 \ 1 \ 0 \ 0 \ 0] \\
  cat &= [0 \ 0 \ 1 \ 0 \ 0] \\
  dog &= [0 \ 0 \ 0 \ 1 \ 0] \\
  elephant &= [0 \ 0 \ 0 \ 0 \ 1]
  \end{align*}
  $$

循环神经网络结构：

<img src="Note_img/a226d9719e4d40169f0a9acd037ceb3e.jpeg" alt="img"  />

### 长短期记忆网络

LSTM 网络结构：

<img src="Note_img/image-20250512111631640.png" alt="image-20250512111631640" style="zoom:33%;" />

* $c^{'} = g(z)f(z_i) + cf(z_i)$

LSTM 不易学习，误差表面相当粗糙：

<img src="Note_img/image-20250512111837073.png" alt="image-20250512111837073" style="zoom:50%;" />

* 原因：

  <img src="Note_img/image-20250512112122111.png" alt="image-20250512112122111" style="zoom: 33%;" />

## 强化学习

强化学习讨论的问题是：在一个复杂不确定的环境中，智能体如何通过与环境进行大量动态交互来（试错）学习一个最优决策策略。

强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。

- **监督学习** 是从外部监督者提供的带标注训练集中进行学习。 **(任务驱动型)**
- **非监督学习** 是一个典型的寻找未标注数据中隐含结构的过程。 **(数据驱动型)**
- **强化学习** 更偏重于智能体与环境的交互， 这带来了一个独有的挑战 ——“**试错（exploration）**”与“**开发（exploitation）**”之间的折中权衡，智能体必须开发已有的经验来获取收益，同时也要进行试探，使得未来可以获得更好的动作选择空间。 **(从错误中学习)**

强化学习主要有以下几个特点：

* 试错学习：通过尝试不同的动作，并根据收到的奖励信号调整策略来学习最优行为。
* 延迟回报：可能需要经过一系列动作后才能得最终的奖励（最后一个状态）。比如 围棋中只有到了最后才能知道胜负。
* 动态策略：智能体需要根据当前状态选择行动，选择动作的策略是动态调整的。
* 序列决策：智能体和环境的交互是一个序列决策过程。

强化学习主要概念：

* 智能体：游戏中玩家所操控的角色
* 环境：道路、障碍物、怪物等智能体外的其它元素
* 状态：当前帧的画面
* 动作：当前可以采取的行动
* 奖励：一般对应着相关任务需求

马尔可夫性质：给定当前状态后，未来状态与过去状态（即该过程的历史状态）是条件独立的。

* 当前状态覆盖了历史中的所有相关信息

马尔可夫决策过程（用一个五元组表示）：

* 状态空间 $S$：所有状态组成的集合

* 动作空间 $A$：所有动作组成的集合

* 转移函数 $p$：刻画了状态之间的转移概率
  $$
  p(s'|s, a) = Pr\{S_{t+1} = s' | S_t = s, A_t = a\}
  $$

  * 表示从 $s$ 经过动作 $a$ 转移到 $s^{'}$ 的概率

* 奖励函数 $R$：不仅取决于当前的状态，还受到动作的影响
  $$
  R_t = R(S_t, a_t, S_{t+1})
  $$

  * 从状态 $S_t$ 经过一个动作 $a_t$ 后转移到状态 $S_{t+1}$ 的奖励

* 折扣因子 $\gamma$，$\gamma \in [0,1]$

策略函数：

* 随机性策略 $\pi(a|s)$：在状态 $s$ 下选择动作 $a$ 的概率
  * $ \sum_{a \in A} \pi(a|s) = 1 $
* 确定性策略 $\pi(s)$：在状态 $s$ 下选择的确定动作
  * $ a = \pi(s) $

策略的具体形式

* 表格策略

  <img src="Note_img/image-20250526153130883.png" alt="image-20250526153130883" style="zoom:67%;" />

* 参数化策略

  <img src="Note_img/image-20250526153156349.png" alt="image-20250526153156349" style="zoom: 67%;" />

回报：回报 $G_t$ 为从时间步 $t$ 开始到终止状态的奖励总和（这里的一系列动作是确定的）

<img src="Note_img/image-20250526170128149.png" alt="image-20250526170128149" style="zoom: 67%;" />
$$
G_t = R_t + \gamma R_{t+1} + \gamma^2 R_{t+2} + \ldots = \sum_{k=0}^{\infty} \gamma^k R_{t+k}
$$

  - 折扣因子 $\gamma \in [0,1]$ 用于衡量未来奖励在当前所具备的价值
    - 加入折扣后可以获得良好的数学性质，如确保一些算法的收敛性
    - 避免马尔可夫过程中的循环导致的无限奖励
    - 未来的奖励具有不确定性，动物和人类在实际场景中也更倾向于即时奖励
    - 考虑真实的经济情况，当前收入相比未来收入具有更强的购买力
  - $k + 1$ 步 ($k \geq 0$) 后的奖励 $R$ 在当前的价值被定义为 $\gamma^k R$

价值函数：用于评估一个**策略**的好坏

- 状态价值函数：以状态 $s$ 为起始状态且按照策略 $\pi$ 行动（如，只要处于上课状态，则2/3学习，1/3走神）得到的期望回报。
  $$
  \begin{align}
  V_{\pi}(s) &= \mathbb{E}_{\pi}[G_t | S_t = s] \\[5pt]
  &= \sum_{a \in A} \pi (a|s) [G_t|S_t = s, A_t=a]
  \end{align}
  $$

  * ==在交互进行的过程中，在给定的起始状态 $S_t$ 和策略 $\pi$ 下可能采取的动作 $a$ 不同，转到不同的状态 $S_{t+1}$，得到的 $R_t$ 也不同，最终的回报 $G_t$ 自然也就不同。==

- 动作价值函数：以状态 $s$（上课）为起始状态且采取动作 $a$（学习），然后按照策略 $\pi$ 行动（有空就复习）得到的期望回报。
  $$
  Q_{\pi}(s, a) \triangleq \mathbb{E}_{\pi}[G_t | S_t = s, A_t = a]
  $$
  
- **==二者关系与计算==**：
  $$
  V_{\pi}(s) = \sum_{a \in A} \pi(a|s) Q_{\pi}(s, a) \\
  Q_{\pi}(s, a) = R^a_s + \gamma \sum_{s' \in \mathcal{S}} p^a_{ss'} V_{\pi}(s')
  $$

  * $p(s'|s, a)$ 记为 $p^a_{ss'}$
  * $R(s, a)$ 记为 $R_s^a$

最优价值函数：
$$
V_*(s) = \max_{\pi} V_{\pi}(s), \forall s \in S \\
Q_*(s, a) = \max_{\pi} Q_{\pi}(s, a)
$$

- $V_*(s)$ 与 $Q_*(s, a)$ 之间的关系：
  $$
  V_*(s) = \max_{a} Q_*(s, a) \\
  Q_*(s, a) = R^a_s + \gamma \sum_{s' \in S} p^a_{ss'} V_*(s')
  $$

  * ==最优策略：可以通过 $Q_*(s, a)$ 得到一个确定性的最优策略。即直接选择**回报**最高的动作==
    $$
    \pi_*(a|s) = 
    \begin{cases} 
    1 & \text{if } a = \arg\max_{a \in \mathcal{A}} Q_*(s, a) \\
    0 & \text{otherwise}
    \end{cases}
    $$

- 

奖励、回报、价值的关系

| 概念 |                             定义                             |
| :--: | :----------------------------------------------------------: |
| 奖励 |                    **单个**动作带来的收益                    |
| 回报 | 一个**固定轨迹**的**奖励的衰减和**（折扣因子 $\gamma \in [0,1]$） |
| 价值 |             某个状态、某个策略下的**回报的期望**             |

==**贝尔曼期望方程（其实就是状态价值函数和动作价值函数的组合）**==：
$$
V_{\pi}(s) = \sum_{a \in \mathcal{A}} \pi(a|s) \left( R^a_s + \gamma \sum_{s' \in \mathcal{S}} p^a_{ss'} V_{\pi}(s') \right) \\

Q_{\pi}(s, a) = R^a_s + \gamma \sum_{s' \in \mathcal{S}} p^a_{ss'} \left(\sum_{a \in A} \pi(a|s') Q_{\pi}(s', a)\right)
$$

> 证明：
> $$
> \begin{align}
> V_{\pi}(s) &= \sum_{a \in A} \pi(a|s) Q_{\pi}(s, a) \\
> &= \sum_{a \in A} \pi(a|s)(R^a_s + \gamma \sum_{s' \in \mathcal{S}} p^a_{ss'} V_{\pi}(s'))
> \end{align}
> $$

* 状态价值函数可以被拆分为即时奖励与后续状态的折扣价值

  动作价值函数也可以被拆分为即时奖励与后续动作的折扣价值

![image-20250526172732933](Note_img/image-20250526172732933.png)

****

### 表格型强化学习

