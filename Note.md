# Artificial Intelligence

## 知识表示和推理

### 前置知识

1. 项：常量、变量和函数

2. ==**置换**==：置换是形如 $\{x_1/t_1, x_2/t_2, \ldots, x_n/t_n\}$ 的有限集合，其中：

   - $\{x_1, x_2, \ldots, x_n\}$ 是互不相同的变量

   - $\{t_1, t_2, \ldots, t_n\}$ 是项（常量、变量或函数）

   - $x_i/t_i$ 表示用 $t_i$ 置换 $x_i$，其==**合法的前提**==是：

     1. 不允许 $t_i$ 和 $x_i$ 相同

     2. 不允许 $x_i$ 出现在 $t_i$ 中，

     3. ==也不允许出现循环置换==

        如：$\{x /y \} \text{和} \{x/f(y), y/{f(x)}\}$

   注意：置换中的每个变量替换是同时进行的

   > 对于 $P(x, g(y, z))$，做置换 $\{x/y, y/f(a)\}$，
   >
   > 即 $P(x, g(y, z)) \{x/y, y/f(a)\} \Rightarrow P(y, g(f(a), z))$

3. 文字：原子公式及其否定

   - $ P $：正文字；$ \neg P $：负文字

   子句：任何文字的析取。某个文字本身也都是子句。

   - $ P \vee \neg Q $ 记作 $ (P, \neg Q) $
   - 空子句：不包含任何文字的子句，记作 NIL
     - 空子句是永假的，不可满足的。

   子句集：由子句构成的集合（子句的合取）

   - $ (P \vee \neg Q) \wedge (P \vee R) $ 记作 $ \{(P, \neg Q), (P, R)\} $

****

特殊符号

1. `⊢*Am`  或者 ``⊢Am`` ：

   公式序列 A1, A2, ..., Am 称作Am的一个证明，如果 Ai (1 ≤ i ≤ m)：
   - 或者是公理；
   - 或者由Aj1, ..., Ajk (j1, ..., jk < i)用推理规则推得。

   当这样的证明存在时，称Am为系统的定理，记作 `|-*Am`（*是形式系统的名称），或者简记为 |-Am

2. `Γ⊢*Am` 或者 `Γ⊢Am`：

   设 Γ 为一公式集合。公式序列 A1, A2, ..., Am 称作 Am 的以 Γ 为前提的演绎，如果 Ai (1 ≤ i ≤ m)：

   - 或者是 Γ 中的公式
   - 或者是公理
   - 或者由 Aj1, ..., Ajk (j1, ..., jk < i) 用推理规则推得。

   当有这样的演绎时，Am 称作 Γ 的演绎结果，记作 `Γ⊢*Am`（*是形式系统的名称），或者简记为 `Γ⊢Am`，称 Γ 和 Γ 的成员为 Am 的前提

3. $\models_i$ 或者 $ \models $：

   如果推理算法 $ i $ 可以根据 $ KB $ 导出结论 $ \alpha $，则形式化地记为：$ KB \models_i \alpha $

   将 $ S $ 逻辑上蕴含 $ C $ 记为 $ S \models C $

4. $\vdash$：

   记某个永真的子句集合为 $ S $，需要推理得到的子句为 $ C $，基于归结的推理过程从 $ S $ 推导出 $ C $ 记为 $ S \vdash C $

### 归结推理

1. 归结式：对于任意两个子句 $C_1$ 和 $C_2$，若 $C_1$ 中有一个文字 $L$，而 $C_2$ 中有一个与 $L$ 成互补的文字 $\neg L$，则分别从 $C_1$ 和 $C_2$ 中删去 $L$ 和 $\neg L$，并将其剩余部分组成新的析取式。这个新的子句被称为 $C_1$ 和 $C_2$ 关于 $L$ 的归结式，$C_1$ 和 $C_2$ 则是该归结式的亲本子句。

   * 子句 $P$ 和 $\neg P$ 的归结式为空子句
   * 子句 $(W, R, Q)$ 和 $(W, S, \neg R)$ 的归结式为 $(W, Q, S)$

   **定理**：两个子句的归结式是这两个子句集的逻辑推论，如 $\{(P, C_1), (\neg P, C_2)\} \models (C_1, C_2)$

2. 如果 $ S \vdash C $，那么 $ S \models C $

   如果 $ S \vdash NIL $，那么 $ S \models NIL $，反之亦然

3. 鲁滨逊归结原理：检查子句集 S 中是否包含空子句，若包含，则 S 不可满足；若不包含，则在 S 中选择合适的子句进行归结，一旦归结出空子句，就说明 S 是不可满足的

5. 合一：在谓词逻辑的归结过程中，寻找项之间合适的变量置换使表达式一致，这个过程称为合一。

   * 用 $ \sigma = \{x_1/t_1, x_2/t_2, \ldots, x_n/t_n\} $ 来表示任一置换。用 $ \sigma $ 对表达式（语句）$ S $ 作置换后的例简记为 $ S\sigma $。

   * 可以对表达式多次置换：如用 $ \theta $ 和 $ \sigma $ 依次对 $ S $ 进行置换，记为 $ (S\theta)\sigma $。其结果等价于先将这两个置换合成（组合）为一个置换，即 $ \theta\sigma $，再用合成置换对 $ S $ 进行置换，即 $ S(\theta\sigma) $

6. 置换复合的过程：

   设 $ \theta = \{x_1/t_1, x_2/t_2, \ldots, x_n/t_n\} $，$ \sigma = \{y_1/u_1, y_2/u_2, \ldots, y_n/u_n\} $

   1. 构成 $\{x_1/t_1 \sigma, \ldots, x_n/ t_n\sigma, y_1/u_1, \ldots, y_m/u_m\}$；
   2. 如果 $y_j \in (x_1, \ldots, x_n)$，则删除 $y_j/u_j$；
   3. 如果 $t_k \sigma = x_k$，则删除 $x_k / t_k \sigma$;

   > 置换的合成公式比较复杂，不妨看个例子
   >
   > 令 $\theta = \{x / f(y), y / z\}, \sigma = \{x / a, y / b, z / y\}$
   >
   > 步骤1：$\theta \sigma = \{x / f(b), y / y, x / a, y / b, z / y\}$
   >
   > 步骤2：删除 $x / a$ 和 $y / b$
   >
   > 步骤3：删除 $y / y$
   >
   > $\theta \sigma = \{x / f(b), z / y\}$

7. 合一项：对于两个语句 $ f $ 和 $ g $，合一项是使得语句 $ f $ 和 $ g $ 等价的一个置换 $ \sigma $。

   最一般合一项：两个语句 $ f $ 和 $ g $ 的最一般合一项 $ \sigma $ 满足：

   - $ \sigma $ 是 $ f $ 和 $ g $ 的一个合一项
   - 对于 $ f $ 和 $ g $ 的任意其它合一项 $ \theta $，存在一个替换 $ \lambda $ 使得 $ \theta = \sigma \lambda $

8. 求最一般合一项：

   给定两个语句 $ f $ 和 $ g $，

   1. 初始化：$ \sigma = \{\}, S = \{f, g\} $
   2. 如果 $ S $ 包含相同的语句，那么停止算法：当前的置换 $ \sigma $ 为语句 $ f $ 和 $ g $ 的最一般合一项目
   3. 否则，找出 $ S $ 的差异集 $ D = \{e_1, e_2\} $：
      - 若 $ e_1 = v $ 是一个变量且 $ e_2 = t $ 是一个不包含 $ v $ 的项，那么令 $ \sigma = \sigma \cup \{v/t\} $，$ S = S \{v/t\} $。返回步骤 2
      - 否则，停止算法：语句 $ f $ 和 $ g $ 不可合一

9. 谓词公式化为子句集的步骤：

   以将下列谓词公式化为子句集为例：$\forall x \Big( \forall y P(x, y) \rightarrow \neg \forall y \big(Q(x, y) \rightarrow R(x, y)\big) \Big)$

   1. 消去谓词公式中的 “→” 和 “↔”
      $$
      \forall x \Big( \neg \forall y P(x, y) \vee \neg \forall y \big( \neg Q(x, y) \vee R(x, y) \big) \Big) \tag{1}
      $$

   2. 把否定符号移到紧靠谓词的位置上，减少否定符号的辖域。
      $$
      \forall x \Big( \exists y \neg P(x, y) \vee \exists y \big( Q(x, y) \wedge \neg R(x, y) \big) \Big) \tag{2}
      $$

   3. 变量标准化：重新命名变元，使每个量词采用不同的变元，从而使不同量词的约束变元有不同的名字。
      $$
      \forall x \Big( \exists y \neg P(x, y) \vee \exists z \big( Q(x, z) \wedge \neg R(x, z) \big) \Big) \tag{3}
      $$

   4. 消去存在量词

      分两种情况：
      $$
      \begin{cases} 
      \exists x \forall y \Big(\neg P(x, z) \vee R \big(x, y, f(a)\big) \Big) \Rightarrow \forall y \Big(\neg P \big(b, g(y) \big) \vee R\big(b, y, f(a)\big)\Big) \\[2ex]
      \forall x_1 \forall x_2 \ldots \forall x_n \exists y P(x_1, x_2, \ldots, x_n, y) \Rightarrow \forall x_1 \forall x_2 \ldots \forall x_n  P(x_1, x_2, \ldots, x_n, f(x_1, x_2, \dots, x_n))
      \end{cases}
      $$
      原式化为：
      $$
      \forall x \bigg( \neg P\big(x, f(x) \big) \vee \Big(Q\big(x, g(x)\big) \wedge \neg R\big(x, g(x)\big) \Big) \bigg) \tag{4}
      $$
      
   5. 化为前束范式
   
   6. 化为合取范式
      $$
      \forall x \bigg( \Big(\neg P\big(x, f(x)\big) \vee Q\big(x, g(x)\big)\Big) \wedge \Big(\neg P\big(x, f(x)\big) \vee \neg R\big(x, g(x)\big)\Big) \bigg) \tag{5}
      $$
   
   7. 略去全称量词
      $$
      \Big(\neg P\big(x, f(x)\big) \vee Q\big(x, g(x)\big)\Big) \wedge \Big(\neg P\big(x, f(x)\big) \vee \neg R\big(x, g(x)\big)\Big) \tag{6}
      $$
   
   8. 消去合取词，把母式用子句集表示
      $$
      \bigg\{\Big(\neg P\big(x, f(x)\big), Q\big(x, g(x)\big)\Big), \Big(\neg P\big(x, f(x)\big), \neg R\big(x, g(x)\big)\Big)\bigg\} \tag{7}
      $$
   
   9. 子句变量标准化，即使每个子句中的变量符号不同
      $$
      \bigg\{\Big(\neg P\big(x, f(x)\big), Q\big(x, g(x)\big)\Big), \Big(\neg P\big(y, f(y)\big), \neg R\big(y, g(y)\big)\Big)\bigg\} \tag{8}
      $$
   
9. 利用归结反演方法来==**证明定理**==的具体步骤为：

   1. 否定目标公式 $G$，得到 $\neg G$；
   2. 将 $\neg G$ 并入到公式集 $F_1 \wedge F_2 \wedge \ldots \wedge F_n$ 中；
   3. 将公式集化子句集，得到子句集 $S$；
   4. 对 $S$ 进行归结，每次归结的结果并入到 $S$ 中。如此反复，直到得到空子句为止。此时，就证明了在前提 $F_1 \wedge F_2 \wedge \ldots \wedge F_n$ 为真时，结论 $G$ 为真。

10. 利用归结推理**==求解问题==**的具体步骤：

   1. 已知前提 $ F $ 用谓词公式表示，并化为子句集 $ S $；

   2. 把待求解的问题 $ P $ 用谓词公式表示，并否定 $ P $，再与 $ answer $ 构成析取式 $ (\neg P \lor answer) $；

   3. 把 $ (\neg P \lor answer) $ 化为子句集，并入到子句集 $ S $ 中，得到子句集 $ S' $；

   4. 对 $ S' $ 应用归结原理进行归结；

   5. 若得到归结式 $ answer $，则答案就在 $ answer $ 中。

10. 支持集策略：

    - 每次归结时，两个亲本子句中至少要有一个是目标公式否定的子句或其后裔。
    - 支持集 = 目标公式否定的子句集合 $\cup$ 这些子句通过归结生成的所有后裔子句

    特点：

    - 尽量避免在可满足的子句集中做归结，因为从中导不出空子句。而求证公式的前提通常是一致的，所以支持集策略要求归结时从目标公式否定的子句出发进行归结。支持集策略实际是一种目标制导的反向推理。
    - 支持集策略是完备的。

****

#### 归结推理的完备性证明

$\text{S is unsatisfiable} \Rightarrow S \vdash ()$

证明：（数学归纳法）

定义 $P(i)$ 表示：当 S 中含有 $i$ 个 literals 时，$\text{S 不可满足} \Rightarrow S \vdash ()$

1. 当 $i = 1$ 时，P(1) 是成立的。

   当 S 是含有 1 个 literal 的子句集时，不妨设含有的 literal 为 P

   $\because$ S 不可满足

   $\therefore$ S 只可能为 ${(P), (¬P)}$

   $\because$ $(P)$ 与 $(¬P)$ 可归结出 $()$

   $\therefore$ $S \vdash ()$

2. 假设：对于 $1 \le i \le k$，$P(i)$ 都成立

   $\because$ S 是含有 $k+1$ 个文字的子句集合，且 S 不可满足。

   从 S 中选取任意 literal，设选取的 literal 为 P。将 S 分为下列 3 个集合：

   * $S_p$：所有含有 P 的子句集
   * $S_{(\neg P)}$：所有含有 $\neg P$ 的子句集
   * $R$：所有不含 $P$ 或 $\neg P$ 的子句集

   $\therefore$ $R$ 是含有 $k$ 个 literal 的 S 的子句集

   情形 1：若 $R$ 不可满足

   $\because$ $P(k)$ 成立。

   $\therefore R \vdash ()$

   $\because R \subseteq S$

   $\therefore S \vdash ()$，即 $P(k + 1)$ 成立

   情形 2：若 R 可满足，即存在解释 $\widetilde{S}$ 使得 R 中的子句全为真。

   $\because$ S 整体不可满足

   $\therefore S_p, S_{(\neg P)}$ 中存在子句使得任意解释下都不满足

   * 若 $S_p$ 为空集，则取解释 $\widetilde{S}$ 并加上 $P$ 的取值为假，$S$ 便可满足。
   * 若 $S_{(\neg P)}$ 为空集，则取解释 $\widetilde{S}$ 并加上 $P$ 的取值为真，$S$ 便可满足。

   $\therefore S_p, S_{(\neg P)}$ 均不能为空集

   $\therefore$ 存在子句 $(P, \alpha)$ 和 $(\neg P, \beta)$ 使得 $P$ 无论取何值，$S$ 都不可满足。这里 $\alpha$ 和 $\beta$ 表示子句中其它不是 $P$ 的 literal

   $\because$ $(P, \alpha)$ 和 $(\neg P, \beta)$ 不论 $P$ 取何值均不能同时满足

   $\therefore$ 在 $\widetilde{S}$ 解释下，$\alpha$ 为假，$\beta$ 为假

   $\because$ $(P, \alpha)$ 和 $(\neg P, \beta)$ 可归结出 $(\alpha, \beta)$，而 $(\alpha, \beta)$ 在解释 $\widetilde{S}$ 下无法满足。令 $ R' = \{\alpha, \beta\} \cup R $

   $\therefore$ $ R' $ 无法满足，且只含有 $ k $ 个 literal

   $\because$ $ P(k) $ 成立

   $\therefore R' \vdash ( ) $，即 $ R' $ 中存在子句可归结出 ( )

   $\because R'$ 中的子句是属于 $ S $ 或由 $ S $ 中子句归结得到

   $\therefore S \vdash ()$ 即 $ P(k+1) $ 成立

****

#### 易错点

1. 判断对错：如果 $ S \models C $，那么 $ S \vdash C $。（错）

   例如：$ P \models (P, Q) $ 成立，但是 $ P $ 不能归结推导出 $ (P, Q) $

## 搜索技术

搜索的性质：

* 完备性：搜索算法是否总能在问题存在解的情况下找到解
* 最优性：当问题中的动作是需要成本时，搜索算法是否首先找到成本最小的解
* 时间复杂度：搜索算法最多需要探索/生成多少个节点来找到解
* 空间复杂度：搜索算法最多需要将多少个节点储存在内存中

****

### 盲目搜索

定义：这些策略都采用固定的规则来选择下一需要被扩展的状态；这些规则不会随着要搜索解决的问题的变化而变化；这些策略不考虑任何与要解决的问题领域相关的信息

| 标准 | 深度优先   | 宽度优先       | 深度受限   | 迭代加深   | 一致代价           |
| ---- | ---------- | -------------- | ---------- | ---------- | ------------------ |
| 时间 | $ O(b^m) $ | $ O(b^{d+1}) $ | $ O(b^L) $ | $ O(b^d) $ | $ O(b^{C^*/s+1}) $ |
| 空间 | $ O(bm) $  | $ O(b^{d+1}) $ | $ O(bL) $  | $ O(bd) $  | $ O(b^{C^*/s+1}) $ |
| 最优 | 否         | 是             | 否         | 是         | 是                 |
| 完备 | 否         | 是             | 否         | 是         | 是                 |

* $ b $：问题中一个状态最大的后继状态个数
* $ d $：是最短解的动作个数
* $ m $：是遍历过程中最长路径的长度
* $ L $：为限制的搜索深度
* $ C^* $ 为最优解的成本
* $ s $ 为动作的成本下界

****

#### 宽度优先搜索

定义：把当前要扩展的状态的后继状态放在边界的最后

性质：完备性、最优性

- 短的路径会在任何比它长的路径之前被遍历
- 给定路径长度，该长度的路径是有限的
- 最终可以遍历所有长度为 $ d $ 的路径，因此一定可以找出最短的解

时间复杂度：$ 1 + b + b^2 + \ldots + b^d + b(b^d - 1) = O(b^{d+1}) $

空间复杂度：$ b(b^d - 1) = O(b^{d+1}) $

* b = 问题中一个状态最大的后继状态个数，d = 最短解的动作个数

![image-20250401171257141](Note_img/image-20250401171257141.png)

#### 深度优先搜索

定义：把当前要扩展的状态的后继状态放在边界的最前面，边界上总是扩展最深的那个节点

完备性：

- 在状态空间无限的情况下：No
- 在状态空间有限，但是存在无限的路径（例如存在回路）的情况下：No
- 在状态空间有限，且对重复路径进行剪枝的情况下：Yes

最优性：No

时间复杂度：$ 1 + b + b^2 + \ldots + b^m - b = O(b^m) $

* 其中 $ m $ 是遍历过程中最长路径的长度，当 $ m $ 远远大于 $ d $ 时，时间效率会很差；当存在多条解路径的情况下深度优先搜索可能比宽度优先搜索更快找到解

空间复杂度：$ (b-1) + (b-1) + \ldots + (b-1) + b = bm - (m-1) = O(bm) $

* 深度优先回溯点 = 当前路径上的点的未扩展过的兄弟节点，一次只会考虑一条路径，边界上只包含当前探索的最深的节点，以及回溯点
* 线性复杂度是深度优先搜索一个显著的优点

![image-20250401172024336](Note_img/image-20250401172024336.png)

#### 一致代价搜索

定义：边界中，按路径的成本升序排列；总是扩展成本**最低**的那条路径

* 当每种动作的成本是一样的时候，和宽度优先是一样的

性质：完备性、最优性

- 一致代价搜索中，所有成本较低的路径都会在成本高的路径之前被扩展
- 给定成本，该成本的路径数量是有限的
- 成本小于最优路径的路径数量是有限的

时间复杂度和空间复杂度：$ O(b^{C^*/s+1}) $

* $ C^* $：最优解的成本
* 假设每个动作的成本 $ \geq s > 0 $

* 当最优解的路径长度为 $ d $ 时，宽度优先搜索的时间和空间复杂度都是 $ O(b^{d+1}) $。由此类比出一致代价搜索的时空复杂度

#### 深度受限搜索

定义：深度优先搜索，但是预先限制了搜索的深度 $ L $，因此无限长度的路径不会导致深度优先搜索无法停止的问题。但只有当解路径的长度 $ \leq L $ 时，才能找到解

完备性：No

最优性：No

时间复杂度：$ O(b^L) $

空间复杂度：$ O(bL) $

* $ L $ 为限制的最大深度

#### 迭代加深搜索

定义：一开始设置深度限制为 $ L = 0 $，我们迭代地增加深度限制，对于每个深度限制都进行深度受限搜索。如果找到解，或者深度受限搜索没有节点可以扩展的时候可以停止当前迭代，并提高深度限制 $ L $。如果没有节点可以被剪掉（深度限制不能再提高）仍然没有找到解，那么说明已经搜索所有路径，因此这个搜索不存在解

完备性：Yes

最优性：Yes（在每个动作的成本一致的情况下）

* 如果动作成本不一致，则可以使用成本边界代替深度限制 $ L $：

  - 只扩展成本低于成本边界的路径

  - 每次迭代时记录当前还未扩展路径中的最小成本
  - 下一次迭代则提高成本边界

  这样开销会很大，迭代数量为成本数值的构成的集合的大小

时间复杂度：$ (d + 1)b^0 + db + (d - 1)b^2 + \ldots + b^d = O(b^d) $

空间复杂度：$ O(bd) $  

特点：迭代加深搜索可以比宽度优先搜索更高效：不用扩展深度限制上的节点。但是宽度优先搜索需要扩展直到目标节点。

### 启发式搜索

启发式函数 $h(n)$：估计从节点 $n$ 到达目标节点的成本

* 对于所有满足目标条件的节点 $n$，$h(n) = 0$

评价函数 $f(n) = g(n) + h(n)$

* $g(n)$：从初始节点到达节点 $n$ 的路径成本
* $f(n)$ 是经过节点 $n$ 从初始节点到达目标节点的路径成本的估计值

****

#### A 搜索

定义：利用节点对应的 $f(n)$ 值来对边界上的节点进行排序，并总扩展边界中具有最小 $f$ 值的节点。

启发函数的上限问题：

<img src="Note_img/image-20250402003130343.png" alt="image-20250402003130343" style="zoom:50%;" />

* $h(A)$ 的估计太大，甚至超出了实际的cost；过大的启发值淹没实际代价 $g(n)$，使得搜索脱离实际；因此启发式函数应该有上限

令 $ f(n) = g(n) + h(n) $ 和 $ f^*(n) = g^*(n) + h^*(n) $（最优路径代价）
$$
\begin{cases}
f(n) \leq f^*(n) \text{ (使得} n \text{点有被扩展的可能性)} \\
g^*(n) \approx g(n) \text{ (逐步优化得到的)}
\end{cases}
$$
可以得出：$ h(n) \leq h^*(n) $

- $ h(n) = 0 $ 退化为一致代价搜索，则可找到最优解，$ h(n) $ 趋于无穷则算法失效
- 如果 $ h(n) $ 高估了实际成本 $ h^*(n) $：这意味着算法可能会认为通过节点 $ n $ 的路径比实际上更糟，从而可能错过最短路径。因为如果 $ h(n) $ 过大，$ f(n) $ 也会相应变大，导致算法倾向于探索其他看似更有希望（即 $ f $ 值更小）的路径，而这些路径可能并不是最优的。
- 如果 $ h(n) $ 精确或低于实际成本 $ h^*(n) $：这样算法就不会错过任何潜在的最短路径，因为它总是偏向于探索那些估计总成本更低的路径。即使 $ h(n) $ 低估了，最坏的结果就是算法会探索更多节点，这可能会使搜索过程更慢，但仍然可以保证找到最优路径。

#### A*搜索

定义：$h(n)$ 是可采纳的 A 算法

时间复杂度和空间复杂度：$ O(b^{C^*/s+1}) $

* 最坏情况下时空复杂度和一致代价搜索一样，但是高效的启发式函数可以大幅度提升性能

$h(n)$ 的可采纳性：对于所有节点 $n$, 满足 $h(n) \le h^*(n)$，则 $h(n)$ 是可采纳的

$h(n)$ 的一致性（单调性）：对于任意节点 $n_1$ 和 $n_2$，若 $h(n_1) \le c(n_1 \rightarrow n_2) + h(n_2)$，则 $h(n)$ 具有 一致性/单调性

* 对 $h(n_1) \le c(n_1 \rightarrow n_2) + h(n_2)$ 左右两边加 $g(n_1)$，得 $g(n_1) + h(n_1) \le g(n_1) + c(n_1 \rightarrow n_2) + h(n_2) \Rightarrow g(n_1) + h(n_1) \le g(n_2) + h(n_2) \Rightarrow f(n_1) \le f(n_2)$
* 如果变成 $\gt$，意味着高估。因为如果假设 $h(n_2) \approx h^*(n_2)$，则 $h(n_1) \gt c(n_1 \rightarrow n_2) + h^*(n_2) = h^*(n_1)$

可采纳性意味着最优性：最优解一定会在所有成本大于 $C^*$ 的路径之前被扩展到

* $C^*$ 为最优解成本

* 证明：

  > 假设 $ p^* $ 是一个最优解的路径；$ p $ 是一条满足 $ c(p) > c(p^*) $ 的路径，而且路径 $ p $ 在 $ p^* $ 之前被扩展。
  >
  > 那么扩展到路径 $ p $ 时，肯定会有一个 $ p^* $ 上的节点 $ n $ 处在边界上
  >
  > 因为 $ p $ 在 $ p^* $ 之前被扩展，则对于 $ p $ 路径上的最后那个节点（假设为目标节点）$ x $ 满足：$ f(x) \leq f(n) $。
  >
  > 因此 $c(p) = f(x) \leq f(n) = g(n) + h(n) \leq g(n) + h^*(n) = c(p^*)$
  >
  > 和 $ c(p) > c(p^*) $ 相矛盾

* 

满足一致性的启发式函数也一定满足可采纳性

* 证明：

  > Case 1: 从节点 $ n $ 没有路径到达目标节点，则可采纳性一定成立
  >
  > Case 2: 假设 $ n = n_1 \rightarrow n_2 \rightarrow \ldots \rightarrow n_k $ 是从节点 $ n $ 到目标节点的一条最优路径。可以使用数学归纳法证明对于所有的 $ i $，$ h(n_i) \leq h^*(n_i) $。
  >
  > Base: $ h(n_k) = 0 $
  >
  > Induction: $ h(n_{i-1}) \leq c(n_i) + h(n_i) \rightarrow h(n_i) \leq c(n_{i-1} \rightarrow n_i) + h^*(n_i) = h^*(n_{i-1}) $

环检测的影响：如果启发式函数只有可采纳性，不一定能在使用了环检测之后仍保持最优性

<img src="Note_img/image-20250402231122962.png" alt="image-20250402231122962" style="zoom:50%;" />

若启发式函数具备单调性，就能在进行环检测之后仍然保持最优性

* 证明：分为三个命题逐步证明

  命题1：一条路径上的节点的 $f$ 函数值是非递减的

  > $\because h(n_1) \le c(n_1 \rightarrow n_2) + h(n_2)$
  >
  > $\therefore g(n_1) + h(n_1) \le g(n_1) + c(n_1 \rightarrow n_2) + h(n_2)$
  >
  > $\therefore g(n_1) + h(n_1) \le g(n_2) + h(n_2)$
  >
  > $\therefore f(n_1) \le f(n_2)$

  命题2：如果节点 $n_2$​ 在节点 $n_1$ 之后被扩展，则有 $f(n_1) \le f(n_2)$

  命题3：使用单调的启发式函数的 $A^*$ 搜索在第一次扩展到某个状态，就是沿着最小成本的路径进行扩展的

  > 假设路径 $p = n_1 \rightarrow n_2 \ldots \rightarrow n_k = n$ 是第一条被发现的到达 $n$ 的路径
  >
  > 假设路径 $p_j = m_1 \rightarrow m_2 \ldots \rightarrow m_j = n$ 是第二条被发现的到达 $n$ 的路径
  >
  > 假设 $c(p)$ 是通过 $p$ 路径到达 $n$ 节点的成本
  >
  > 假设 $c(p_j)$ 是通过 $p_j$ 路径到达 $n$ 节点的成本
  >
  > 根据命题2，$c(p) + h(n) \leq c(p_j) + h(n)$
  >
  > 因此 $c(p) \leq c(p_j)$

#### IDA*

A*搜索和宽度优先搜索或一致代价搜索一样，也存在潜在的空间复杂度过大的问题。

``IDA*``（迭代加深的 ``A*`` 搜索）：用于解决空间复杂度过大的问题，它类似于迭代加深算法，但是IDA*用于划定界限的不是深度，而是 $ f $ 值，即 $ g + h $ 。

在每次迭代时，IDA* 划定的界限是 $ f $ 值超过上次迭代的界限最少的节点的 $ f $ 值。
