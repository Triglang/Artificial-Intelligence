import torch
from torch import optim
from torch.nn.functional import softmax
from torch.utils.data import DataLoader, random_split
import argparse
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
from tqdm import tqdm
import logging
from time import time
import os

from mlp import MLP
from dataset import Mnist1DDataset
import tracemalloc
from logging import FileHandler

import matplotlib
matplotlib.use('Agg')  # æ— GUIç¯å¢ƒå¿…å¤‡
import matplotlib.pyplot as plt

parser = argparse.ArgumentParser()
# model hyperparameters
parser.add_argument('--input_dim', type=int, default=28*28, help='input dimension')
parser.add_argument('--hidden_dim', type=int, default=128, help='hidden dimension')
parser.add_argument('--out_dim', type=int, default=10, help='output dimension')
parser.add_argument('--num_layer', type=int, default=2, help='number of hidden layers')
parser.add_argument('--activation', type=str, default='sigmoid', help='activation function')

# dataset parameters
parser.add_argument('--data_path', type=str, default='./data/mnist/', help='path to dataset')

# train parameters
parser.add_argument('--batch_size', type=int, default=64, help='batch size, default: 64')
parser.add_argument('--dropout', type=float, default=0.1, help='dropout rate, default: 0.1')
parser.add_argument('--device', type=str, choices=['cuda', 'cpu'], default='cpu', help='device')
parser.add_argument('--optimizer', type=str, default='SGD',\
                    help='set optimizer type in [SGD/Adam/AdamW...], default: SGD')
parser.add_argument('--lr', type=float, default=1e-3,\
                    help='set learning rate, default: 1e-3')
parser.add_argument('--epoch', type=int, default=400, help='epoch to train, default: 400')
parser.add_argument('--patience', type=int, default=20, help='epoch to stop training, default: 20')
parser.add_argument('--log_file', type=str, default='log/log.txt',\
                    help='log file name, default: log/log.txt')
parser.add_argument('--save_path', type=str, default='model/best.pt',\
                    help='path to save model, default: model/best.pt')
parser.add_argument('--loss_img', type=str, default='log/loss.png', help='path to save loss image, default: log/loss.png')


DEBUG = 0

def main():
    args = parser.parse_args()
    if DEBUG:
        print(args)
    
    if not os.path.exists('/'.join(args.log_file.split('/')[:-1])):
        os.makedirs('/'.join(args.log_file.split('/')[:-1]))
    if not os.path.exists('/'.join(args.save_path.split('/')[:-1])):
        os.makedirs('/'.join(args.save_path.split('/')[:-1]))

    # logging.basicConfig(
    #     filename=args.log_file, 
    #     filemode="w", 
    #     format="[%(asctime)s]:%(levelname)s: %(message)s", 
    #     datefmt="%d-%M-%Y %H:%M:%S", 
    #     level=logging.DEBUG
    # )
    # åˆ›å»º FileHandler å¹¶æŒ‡å®šç¼–ç 
    file_handler = FileHandler(
        filename=args.log_file,  # ä½¿ç”¨ä¼ å…¥çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
        mode='w',                # è¦†ç›–æ¨¡å¼ï¼ˆåŸ filemode='w'ï¼‰
        encoding='utf-8'         # æŒ‡å®š UTF-8 ç¼–ç 
    )

    # æ­£ç¡®é…ç½® logging
    logging.basicConfig(
        format="[%(asctime)s]:%(levelname)s: %(message)s",
        datefmt="%d-%M-%Y %H:%M:%S",
        level=logging.DEBUG,
        handlers=[file_handler]  # åªé€šè¿‡ handlers ä¼ é€’
    )

    # è·å–æ•°æ®é›†
    torch.manual_seed(time())
    if 'mnist' in args.data_path:
        data_set = Mnist1DDataset(args.data_path, set_type='train')
        test_set = Mnist1DDataset(args.data_path, set_type='test')

        train_size = data_set.__len__() // 5 * 4
        val_size = data_set.__len__() - train_size
        train_set, val_set = random_split(data_set, [train_size, val_size])
    
        train_loader = DataLoader(
            train_set, 
            batch_size=args.batch_size, 
            shuffle=True,
            collate_fn=Mnist1DDataset.collate_fn
        )
        val_loader = DataLoader(
            val_set, 
            batch_size=args.batch_size, 
            shuffle=True,
            collate_fn=Mnist1DDataset.collate_fn
        )
        test_loader = DataLoader(
            test_set, 
            batch_size=args.batch_size, 
            shuffle=True,
            collate_fn=Mnist1DDataset.collate_fn
        )
    else:
        raise ValueError('Invalid dataset path')

    category = data_set.category
    
    device = torch.device(args.device)
    # å£°æ˜æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = MLP(
        input_dim=args.input_dim,
        hidden_dim=args.hidden_dim,
        out_dim=args.out_dim,
        device=device,
        num_layers=args.num_layer,
        activation=args.activation,
        dropout=args.dropout
    )
    model = model.set_device(device)


    # claim the loss function
    criterion = torch.nn.CrossEntropyLoss()     # äº¤å‰ç†µæŸå¤±è¡¡é‡

    # claim the optimizer
    if args.optimizer.lower() == 'sgd':
        optimizer = optim.SGD(model.parameters(), lr=args.lr)
    elif args.optimizer.lower() == 'adam':
        optimizer = optim.Adam(model.parameters(), lr=args.lr)
    elif args.optimizer.lower() == 'adamw':
        optimizer = optim.AdamW(model.parameters(), lr=args.lr)
    else:
        raise ValueError(f"Unsupported optimizer: {args.optimizer}")
    
    start = 1
    early_stop_count = 0
    best_val_f1 = 0.

    train_acc = []
    train_f1 = []
    train_loss = []

    val_acc = []
    val_f1 = []
    val_loss = []

    
    for epoch in tqdm(range(start, args.epoch + 1), desc="[Total Training]", position=0):
        logging.info('[epoch: {:d}] '.format(epoch))

        # è®­ç»ƒæ¨¡å‹
        truth = []
        predict = []
        total_loss = 0.
        
        # åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹
        model.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œä½¿å¾—dropoutç”Ÿæ•ˆ
        for pack_images, y in train_loader:
            # put the data above to device
            pack_images = pack_images.to(device)
            y = y.to(device)
            
            # è®°å½•çœŸå®æ ‡ç­¾
            truth = truth + y.tolist()

            # forward and backward
            optimizer.zero_grad()          # æ¸…é›¶æ¢¯åº¦
            output = model(pack_images)     # å‰å‘è®¡ç®— [batch_size, out_dim]
            loss = criterion(output, y)    # è®¡ç®—æŸå¤±
            loss.backward()                # åå‘ä¼ æ’­
            optimizer.step()               # æ›´æ–°å‚æ•°

            # è®°å½•é¢„æµ‹ç»“æœå’ŒæŸå¤±
            predict += output.argmax(dim=1).tolist()  # å–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœ
            total_loss += loss.item()      # ç´¯åŠ æŸå¤±å€¼
            if DEBUG:
                print(predict)
                print(truth)
                print(total_loss)

        logging.info('average loss: {:.4f}'.format(total_loss * args.batch_size / len(train_loader)))
        train_loss.append(total_loss / len(train_loader))

        acc = accuracy_score(truth, predict)
        marco_f1 = f1_score(truth, predict, average='macro')
        precision = precision_score(truth, predict, average='macro')
        recall = recall_score(truth, predict, average='macro')

        logging.info('train acc: {:.4f}, f1: {:.4f}, precision: {:.4f}, recall: {:.4f}'.format(
            acc,
            marco_f1, 
            precision, 
            recall)
        )
        train_acc.append(acc)
        train_f1.append(marco_f1)
        
        # åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•å¹¶ä¿å­˜æœ€å¥½çš„æ¨¡å‹
        logging.info('======')
        logging.info('test model on val set')
        truth = []
        predict = []
        total_loss = 0.

        model.eval() # è®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œä½¿å¾—dropoutä¸ç”Ÿæ•ˆ
        for pack_images, y in val_loader:
            with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
                pack_images = pack_images.to(device)
                y = y.to(device)

                truth = truth + y.tolist()

                output = model(pack_images)      # å‰å‘è®¡ç®—
                loss = criterion(output, y)     # è®¡ç®—æŸå¤±
                # è®°å½•ç»“æœ
                predict += output.argmax(dim=1).tolist()
                total_loss += loss.item()
        acc = accuracy_score(truth, predict)
        marco_f1 = f1_score(truth, predict, average='macro')
        precision = precision_score(truth, predict, average='macro')
        recall = recall_score(truth, predict, average='macro')

        logging.info('val loss: {:.4f}'.format(total_loss * args.batch_size / len(val_loader)))
        logging.info('val acc: {:.4f}, f1: {:.4f}, precision: {:.4f}, recall: {:.4f}'.format(
            acc,
            marco_f1, 
            precision, 
            recall)
        )
        logging.info('early stop counter: {:d}'.format(early_stop_count))
        logging.info('========================================')
        val_loss.append(total_loss / len(val_loader))
        val_acc.append(acc)
        val_f1.append(marco_f1)

        # save the best model or ignore this code
        if marco_f1 > best_val_f1:
            best_val_f1 = marco_f1
            # ä¿å­˜æ¨¡å‹å‚æ•°
            torch.save(model.state_dict(), args.save_path)
            logging.info(f"ğŸŒŸ å‘ç°æ–°æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯F1åˆ†æ•°: {best_val_f1:.4f}")
            early_stop_count = 0  # é‡ç½®æ—©åœè®¡æ•°å™¨
        else:
            early_stop_count += 1
            logging.warning(f"æ—©åœè®¡æ•°å™¨: {early_stop_count}/{args.patience}")

        #==============================================

        # æ—©åœï¼šéªŒè¯é›†ä¸Šè¿ç»­å¤šæ¬¡æ€§èƒ½æµ‹è¯•æ²¡æœ‰æå‡ï¼Œåˆ™åœæ­¢è®­ç»ƒ
        ###############################################
        # set your early stop condition here
        # or ignore this code
        # æ—©åœåˆ¤æ–­
        if early_stop_count >= args.patience:
            logging.warning(f"æ—©åœè§¦å‘ï¼è¿ç»­ {args.patience} è½®éªŒè¯F1æœªæå‡")
            break  # ç»ˆæ­¢è®­ç»ƒå¾ªç¯
        ###############################################
    
    # end train for loop   
    loss_img_dir = os.path.dirname(args.loss_img)
    if not os.path.exists(loss_img_dir):
        os.makedirs(loss_img_dir)

    # ç”Ÿæˆå•ç‹¬çš„æ–‡ä»¶å
    train_loss_path = os.path.join(loss_img_dir, "train_loss.png")
    val_loss_path = os.path.join(loss_img_dir, "val_loss.png")

    # ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_loss, label='Training Loss', color='blue', linewidth=2)
    plt.title('Training Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.savefig(train_loss_path, bbox_inches='tight', dpi=300)
    plt.close()

    # ç»˜åˆ¶éªŒè¯æŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(val_loss, label='Validation Loss', color='orange', linewidth=2)
    plt.title('Validation Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.savefig(val_loss_path, bbox_inches='tight', dpi=300)
    plt.close()

    #  åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•
    truth = []
    predict = []
    total_loss = 0.
    logging.info('test model on test set')

    model.eval()
    for pack_images, y in tqdm(test_loader, desc="[test on test set] ", leave=False):
        with torch.no_grad():
            pack_images = pack_images.to(device)
            y = y.to(device)
            
            truth = truth + y.tolist()

            output = model(pack_images)         # å‰å‘è®¡ç®—
            loss = criterion(output, y)        # è®¡ç®—æŸå¤±
            
            # è®°å½•ç»“æœ
            predict += output.argmax(dim=1).tolist()
            total_loss += loss.item()

    acc = accuracy_score(truth, predict)
    marco_f1 = f1_score(truth, predict, average='macro')
    precision = precision_score(truth, predict, average='macro')
    recall = recall_score(truth, predict, average='macro')
    logging.info('test loss: {:.4f}'.format(total_loss * args.batch_size / len(test_loader)))
    logging.info('test acc: {:.4f}, f1: {:.4f}, precision: {:.4f}, recall: {:.4f}'.format(
        acc,
        marco_f1, 
        precision, 
        recall)
    )
    logging.info('classification report:')
    logging.info('\n' + str(classification_report(
        truth, predict, labels = category, digits = 4
    )))

# end main()

if __name__ == '__main__':
    tracemalloc.start()
    main()
    current_mem, peak_mem = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    logging.info(f"peak memory usage: {peak_mem / 10**6}MB")
